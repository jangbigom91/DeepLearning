{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d080ddd2",
   "metadata": {},
   "source": [
    "# 실습 2 - 하진기, 이재원, 성유기, 천민우 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb1049",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, split (X), sampling(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbd0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, minmax_scale, robust_scale\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91db91",
   "metadata": {},
   "source": [
    "### 데이터 준비  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9229ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df8023",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97524ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a97398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Amount', ylabel='Density'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAE9CAYAAACC1v/2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAknUlEQVR4nO3dfZBc1Xnn8e8zM5IMAgyYMVF4sYQjkshex8YKkPLam2zKQaKyVpzEW2A7eIkThQok9rp2yziuSnmzS63XyboqxDYy8VIxXjsKCcFRNvICIYld2ZgXsSaYN4EA22hRQEAiwMKC6X72j3t71Gp6Zno09/RoOt9PVVd3377n9rlzafhxzj3nRGYiSZKkpWtssSsgSZKkhTHQSZIkLXEGOkmSpCXOQCdJkrTEGegkSZKWOAOdJEnSEjex2BVYTCeddFKuXr16sashSZI0pzvvvPOpzJzs99k/60C3evVqduzYsdjVkCRJmlNEfHumz+xylSRJWuIMdJIkSUucgU6SJGmJM9BJkiQtcQY6SZKkJc5AJ0mStMQZ6CRJkpY4A50kSdISZ6CTJEla4gx0kiRJS5yBbkhue+RpfvPP7lnsakiSpBFkoBuSrz20l2u/PuMSbJIkSYfNQDckrXb13G7n4lZEkiSNHAPdkGRWQa6VBjpJktQsA92QtOqWuZYtdJIkqWEGuiHp5Li2LXSSJKlhBroh6QQ5W+gkSVLTDHRD0gly7fYiV0SSJI0cA92QtB0UIUmSCjHQDYldrpIkqRQD3ZB0ulodFCFJkppmoBuSTlfrlC10kiSpYQa6Iem0zLlShCRJapqBbkjaTiwsSZIKKRroImJDROyMiF0RcXmfzyMirqw/vzsizpqrbET853rfuyLipoj4/q7PPlLvvzMizit5bvPVys6zgU6SJDWrWKCLiHHg08BGYB1wYUSs69ltI7C2fmwGrhqg7G9n5hsy843A/wJ+sy6zDrgAeB2wAfhMfZwjgl2ukiSplJItdGcDuzLzkcx8EdgKbOrZZxNwbVZuBY6PiFWzlc3MZ7vKrwSy61hbM/NAZj4K7KqPc0SY7nK1hU6SJDWsZKA7BXis6/3uetsg+8xaNiKuiIjHgPdQt9AN+H1ExOaI2BERO/bu3TuvE1oI56GTJEmllAx00Wdbb5qZaZ9Zy2bmRzPzNOCLwGXz+D4y8+rMXJ+Z6ycnJ/tWvIRWZx46l/6SJEkNKxnodgOndb0/FXh8wH0GKQvwJeDn5vF9iyZd+kuSJBVSMtDdAayNiDURsZxqwMK2nn22ARfVo13PBfZl5p7ZykbE2q7y7wAe6DrWBRGxIiLWUA20uL3Uyc1Xyy5XSZJUyESpA2fmVERcBtwIjAPXZOa9EXFJ/fkWYDtwPtUAhv3AxbOVrQ/98Yj4QaANfBvoHO/eiLgOuA+YAi7NzFap85uvTo5z6S9JktS0YoEOIDO3U4W27m1bul4ncOmgZevtP9dn985nVwBXHG59S3JiYUmSVIorRQxJJ8g5D50kSWqagW5IOl2tUwY6SZLUMAPdkLQd5SpJkgox0A3J9KAIW+gkSVLDDHRD0nJQhCRJKsRANySdiYWdtkSSJDXNQDckBycWXuSKSJKkkWOgG5JOkHNQhCRJapqBbkimu1y9h06SJDXMQDckDoqQJEmlGOiGxHnoJElSKQa6IXEeOkmSVIqBbkhsoZMkSaUY6IbEe+gkSVIpBrohaRvoJElSIQa6IenkOAOdJElqmoFuSFou/SVJkgox0A1JuvSXJEkqxEA3JJ2uVlvoJElS0wx0Q+I9dJIkqRQD3ZA4ylWSJJVioBuStoMiJElSIQa6IWmlLXSSJKkMA92QtOvRrS79JUmSmmagG5LpLldb6CRJUsMMdEPSch46SZJUiIFuCDKTnJ62xEQnSZKaZaAbgu5eVu+hkyRJTTPQDUH3VCV2uUqSpKYZ6Iage6oSB0VIkqSmGeiG4JAWOrtcJUlSw4oGuojYEBE7I2JXRFze5/OIiCvrz++OiLPmKhsRvx0RD9T73xARx9fbV0fECxFxV/3YUvLc5qO7Uc4WOkmS1LRigS4ixoFPAxuBdcCFEbGuZ7eNwNr6sRm4aoCyNwOvz8w3AA8CH+k63sOZ+cb6cUmZM5u/7i5XW+gkSVLTSrbQnQ3sysxHMvNFYCuwqWefTcC1WbkVOD4iVs1WNjNvysypuvytwKkFz6ERecigCAOdJElqVslAdwrwWNf73fW2QfYZpCzALwJf6Xq/JiK+ERFfjYi3Hm7Fm3bIoAhb6CRJUsMmCh47+mzrTTMz7TNn2Yj4KDAFfLHetAc4PTOfjog3A1+OiNdl5rM95TZTde9y+umnz3kSTThkHjpb6CRJUsNKttDtBk7ren8q8PiA+8xaNiLeB/w08J6s+zMz80BmPl2/vhN4GDizt1KZeXVmrs/M9ZOTk4d5avPjPHSSJKmkkoHuDmBtRKyJiOXABcC2nn22ARfVo13PBfZl5p7ZykbEBuDDwDsyc3/nQBExWQ+mICLOoBpo8UjB8xtYd6Czy1WSJDWtWJdrZk5FxGXAjcA4cE1m3hsRl9SfbwG2A+cDu4D9wMWzla0P/SlgBXBzRADcWo9ofRvwWxExBbSASzLzmVLnNx/d3axTdrlKkqSGlbyHjszcThXaurdt6XqdwKWDlq23/8AM+18PXL+Q+pbSbne/NtBJkqRmuVLEELSdtkSSJBVkoBuClkt/SZKkggx0Q9A9sbBdrpIkqWkGuiHonqrEFjpJktQ0A90QtG2hkyRJBRnohqB7IIQtdJIkqWkGuiHotNCNhStFSJKk5hnohqDTQLdsfMwuV0mS1DgD3RB0ulyXjY/Z5SpJkhpnoBuCzrQly8bDFjpJktQ4A90QdFroJsbHXMtVkiQ1zkA3BJ0Mt3x8zKW/JElS4wx0Q9AZ5ToxHofMSSdJktQEA90QtLNrUIQtdJIkqWEGuiHoHuVqC50kSWqagW4I2l2jXG2hkyRJTTPQDUG7Xh3CLldJklSCgW4IWt3z0JnnJElSwwx0Q5AOipAkSQUZ6Iag1d3l6qAISZLUMAPdELRd+kuSJBVkoBuCQ+ahs4VOkiQ1zEA3BN3z0GViK50kSWqUgW4IOvlt2XgA2EonSZIaZaAbgk6L3MR49ed2pKskSWqSgW4IOvfQLa8Dnct/SZKkJhnohqDTxToxVne52kInSZIaZKAbgul76CbqFrr2IlZGkiSNHAPdELS7RrmCgyIkSVKzDHRDcPAeOrtcJUlS8wx0Q9DqaaFzUIQkSWpS0UAXERsiYmdE7IqIy/t8HhFxZf353RFx1lxlI+K3I+KBev8bIuL4rs8+Uu+/MyLOK3lu89EJcE5bIkmSSigW6CJiHPg0sBFYB1wYEet6dtsIrK0fm4GrBih7M/D6zHwD8CDwkbrMOuAC4HXABuAz9XEWXSe/2eUqSZJKKNlCdzawKzMfycwXga3App59NgHXZuVW4PiIWDVb2cy8KTOn6vK3Aqd2HWtrZh7IzEeBXfVxFl2rZ2Jhu1wlSVKTSga6U4DHut7vrrcNss8gZQF+EfjKPL5vUWT2jHK1hU6SJDWoZKCLPtt6k8xM+8xZNiI+CkwBX5zH9xERmyNiR0Ts2Lt3b58izWvV884ts8tVkiQVUDLQ7QZO63p/KvD4gPvMWjYi3gf8NPCezOn+y0G+j8y8OjPXZ+b6ycnJeZ3Q4ZoeFDHmPHSSJKl5JQPdHcDaiFgTEcupBixs69lnG3BRPdr1XGBfZu6ZrWxEbAA+DLwjM/f3HOuCiFgREWuoBlrcXvD8BtbOJALGXfpLkiQVMFHqwJk5FRGXATcC48A1mXlvRFxSf74F2A6cTzWAYT9w8Wxl60N/ClgB3BwRALdm5iX1sa8D7qPqir00M1ulzm8+Wu1kPGI60Ln0lyRJalKxQAeQmdupQlv3ti1drxO4dNCy9fYfmOX7rgCuONz6ltJOGIugHhNhl6skSWqUK0UMQTuTsbEq1IFdrpIkqVkGuiFot5OxiOlBEc5DJ0mSmmSgG4JWVvfQjXW6XG2hkyRJDTLQDUEm1SjX6AyKMNBJkqTmDDQoIiKuB64BvpKZjtGcp1Y7mWonf/XAkwDcfP8TfOvp/X33ffc5pw+zapIkaQQM2kJ3FfBu4KGI+HhE/FDBOo2cah66oJ5mBW+hkyRJTRoo0GXmX2bme4CzgG9RzQH3dxFxcUQsK1nBUdDOZAyop6FzUIQkSWrUwPfQRcSrgH8H/BLwDeB3qQLezUVqNkJa7WqlCFvoJElSCYPeQ/enwA8BXwD+Tb08F8AfRcSOUpUbFe2swlynhc5RrpIkqUmDrhTxuXrlhmkRsSIzD2Tm+gL1GinVPHRdLXSLXB9JkjRaBu1y/S99tn29yYqMss6giLGu95IkSU2ZtYUuIr4POAU4KiLeBNSdhhwHHF24biOjldUfbmz6HjoDnSRJas5cXa7nUQ2EOBX4ZNf254DfKFSnkdPOaumvmB7lurj1kSRJo2XWQJeZnwc+HxE/l5nXD6lOI6ddj3IdG7OFTpIkNW+uLtf3Zub/BFZHxId6P8/MT/Ypph6tdtVC1+lytYVOkiQ1aa4u15X18zGlKzLK2vVaruHEwpIkqYC5ulw/Wz//p+FUZzRVo1y7B0UscoUkSdJIGWjakoj4REQcFxHLIuKWiHgqIt5bunKjop1J4LQlkiSpjEHnofupzHwW+GlgN3Am8B+L1WrEtHonFjbPSZKkBg0a6JbVz+cDf5iZzxSqz0jKnqW/bKGTJElNGnTprz+PiAeAF4BfjYhJ4HvlqjVaWvW0JeEoV0mSVMBALXSZeTnwY8D6zHwJ+C6wqWTFRklnYuFOC53z0EmSpCYN2kIH8MNU89F1l7m24fqMpGpQRHcLnYFOkiQ1Z6BAFxFfAF4L3AW06s2JgW4gBycWrt7b5SpJkpo0aAvdemBd2ld4WA5OLBwEdrlKkqRmDTrK9R7g+0pWZJR1JhaGanJhW+gkSVKTBm2hOwm4LyJuBw50NmbmO4rUasR0JhaGqqXOFjpJktSkQQPdx0pWYtS12kzfP2cLnSRJatpAgS4zvxoRrwHWZuZfRsTRwHjZqo2OrKctAVvoJElS8wZdy/WXgT8BPltvOgX4cqE6jZzOxMJgC50kSWreoIMiLgXeAjwLkJkPAa8uValR0+ppoXMeOkmS1KRBA92BzHyx86aeXNhUMqCspy2BqoXOPCdJkpo0aKD7akT8BnBURLwd+GPgz+cqFBEbImJnROyKiMv7fB4RcWX9+d0RcdZcZSPiXRFxb0S0I2J91/bVEfFCRNxVP7YMeG7FdSYWhmpwhC10kiSpSYOOcr0ceD/wTeBXgO3A52YrEBHjwKeBtwO7gTsiYltm3te120Zgbf04B7gKOGeOsvcAP8vB+/m6PZyZbxzwnIams/QXVJMLew+dJElq0qCjXNsR8WXgy5m5d8Bjnw3sysxHACJiK7AJ6A50m4Br6xUobo2I4yNiFbB6prKZeX+9bcBqLL52O6frO+YoV0mS1LBZu1zrLtGPRcRTwAPAzojYGxG/OcCxTwEe63q/u942yD6DlO1nTUR8IyK+GhFvHWD/oWjnwXnoqhY6A50kSWrOXPfQfZBqdOuPZuarMvNEqq7Rt0TEv5+jbL8mtN4kM9M+g5TttQc4PTPfBHwI+FJEHPeySkVsjogdEbFj795BGxsXpnXI0l/Y5SpJkho1V6C7CLgwMx/tbKi7Qd9bfzab3cBpXe9PBR4fcJ9Byh4iMw9k5tP16zuBh4Ez++x3dWauz8z1k5OTc5xCMw7tcg27XCVJUqPmCnTLMvOp3o31fXTL5ih7B7A2ItZExHLgAmBbzz7bgIvqrt1zgX2ZuWfAsoeIiMl6MAURcQbVQItH5qjjUHQPinBiYUmS1LS5BkW8eJifkZlTEXEZcCPVMmHXZOa9EXFJ/fkWqtGy5wO7gP3AxbOVBYiIdwK/B0wCfxERd2XmecDbgN+KiCmgBVySmc/McX5D0T1tiUt/SZKkps0V6H4kIp7tsz2AV8x18MzcThXaurdt6XqdVKtQDFS23n4DcEOf7dcD189Vp8XQO7GwLXSSJKlJswa6zBwfVkVGWe/SX+kiG5IkqUGDrhShBfAeOkmSVJKBbgja7YMTIYdLf0mSpIYZ6IagnTk9sXA1bcni1keSJI0WA90QdE8sHFHNSydJktQUA11hmVmPcj04sbBdrpIkqUkGusI6jXHdS38Z5yRJUpMMdIW16kQ3PW0JttBJkqRmGegK64S36WlLxhwUIUmSmmWgK6wT6Mam76Fz2hJJktQsA11hvffQhRMLS5KkhhnoCuvcQxddLXRpC50kSWqQga6w9vSgCOpnW+gkSVKzDHSF9Q6KCGyhkyRJzTLQFdbK3i5XW+gkSVKzDHSF5csGRdhCJ0mSmmWgK6x3YuGxCFrmOUmS1CADXWEH56Gr3ttCJ0mSmmagK6zdrp6D7nvoDHSSJKk5BrrCpke5Tk9bgkt/SZKkRhnoCus/ytVEJ0mSmmOgK6x3YuGIsIVOkiQ1ykBX2MG1XA8u/WULnSRJapKBrrDptVzr97bQSZKkphnoCuudtmQsIHHqEkmS1BwDXWHtnkERnWeX/5IkSU0x0BXWCW7dLXRgC50kSWqOga6w6XvouqYtAVvoJElScwx0hfVOLBy20EmSpIYZ6AprT49ytYVOkiSVYaArrJW9EwtXz85FJ0mSmlI00EXEhojYGRG7IuLyPp9HRFxZf353RJw1V9mIeFdE3BsR7YhY33O8j9T774yI80qe26DyZRMLd1roDHSSJKkZxQJdRIwDnwY2AuuACyNiXc9uG4G19WMzcNUAZe8Bfhb4Ws/3rQMuAF4HbAA+Ux9nUbXavfPQVS/Mc5IkqSklW+jOBnZl5iOZ+SKwFdjUs88m4Nqs3AocHxGrZiubmfdn5s4+37cJ2JqZBzLzUWBXfZxF1TsP3ZhdrpIkqWElA90pwGNd73fX2wbZZ5Cyh/N9Qzcd6Or3YQudJElqWMlAF3229caYmfYZpOzhfB8RsTkidkTEjr17985xyIVrt6vnMVvoJElSISUD3W7gtK73pwKPD7jPIGUP5/vIzKszc31mrp+cnJzjkAvXetk8dLbQSZKkZpUMdHcAayNiTUQspxqwsK1nn23ARfVo13OBfZm5Z8CyvbYBF0TEiohYQzXQ4vYmT+hwTM9D17P0ly10kiSpKROlDpyZUxFxGXAjMA5ck5n3RsQl9edbgO3A+VQDGPYDF89WFiAi3gn8HjAJ/EVE3JWZ59XHvg64D5gCLs3MVqnzG1S7Z9qSznN7sSokSZJGTrFAB5CZ26lCW/e2LV2vE7h00LL19huAG2YocwVwxQKq3LjpiYXr92Mu/SVJkhrmShGF5fRKES79JUmSyjDQFdZq9w6KqJ7bJjpJktQQA11hvffQHVwpwkAnSZKaYaArrHeU63QLnXlOkiQ1xEBXWGume+jmnCdZkiRpMAa6wnqX/hpzYmFJktQwA11hTiwsSZJKM9AVNtPEwuY5SZLUFANdYZ1pS8ZsoZMkSYUY6Apr9wyKsIVOkiQ1zUBX2MsHRRy6XZIkaaEMdIXNdA+d89BJkqSmGOgK6136q/MHd6UISZLUFANdYe32DBMLG+gkSVJDDHSFHexyPfTZLldJktQUA11hrRlXijDRSZKkZhjoCstMxuLgYIixMQdFSJKkZhnoCmu1c7pVDrq7XE10kiSpGQa6wtp5sFUOurtcF6tGkiRp1BjoCmvXXa4dY13bJUmSmmCgK6zVTsYP6XK1hU6SJDXLQFdY1ULX3eV6cLskSVITDHSFtdt5yD10ttBJkqSmGegKayeMj9lCJ0mSyjHQFdbqGRQR4Tx0kiSpWQa6wnKGe+hcKUKSJDXFQFfYyycWDgK7XCVJUnMMdIX13kMH1WoRdrlKkqSmGOgKa7eTODTPMT4WtE10kiSpIQa6wlqZL2uhO2rZOPtfai1SjSRJ0qgx0BXWTg65hw7gmBUTfPfA1CLVSJIkjRoDXWHt9qHTlgCsXDHB8wY6SZLUkKKBLiI2RMTOiNgVEZf3+Twi4sr687sj4qy5ykbEiRFxc0Q8VD+fUG9fHREvRMRd9WNLyXMbVLtPl6stdJIkqUnFAl1EjAOfBjYC64ALI2Jdz24bgbX1YzNw1QBlLwduycy1wC31+46HM/ON9eOSMmc2P73TlkAV6GyhkyRJTSnZQnc2sCszH8nMF4GtwKaefTYB12blVuD4iFg1R9lNwOfr158HfqbgOSxYv3voVq6Y4KVWcmDKgRGSJGnhSga6U4DHut7vrrcNss9sZU/OzD0A9fOru/ZbExHfiIivRsRb+1UqIjZHxI6I2LF37975ntO8tTMZ6/krH7NiAoDvHjDQSZKkhSsZ6KLPtt7J12baZ5CyvfYAp2fmm4APAV+KiONedpDMqzNzfWaun5ycnOOQC9dqJ+N9WugAu10lSVIjSga63cBpXe9PBR4fcJ/Zyj5Rd8tSPz8JkJkHMvPp+vWdwMPAmY2cyQK0M4k+99ABDoyQJEmNKBno7gDWRsSaiFgOXABs69lnG3BRPdr1XGBf3Y06W9ltwPvq1+8D/gwgIibrwRRExBlUAy0eKXd6g+k3ynXlinHAFjpJktSMiVIHzsypiLgMuBEYB67JzHsj4pL68y3AduB8YBewH7h4trL1oT8OXBcR7we+A7yr3v424LciYgpoAZdk5jOlzm9Q7TYzdrnaQidJkppQLNABZOZ2qtDWvW1L1+sELh20bL39aeAn+2y/Hrh+gVVuXCtfvpbrsvExVkyM2UInSZIa4UoRhWWfLldwLjpJktQcA11h/SYWhqrb1S5XSZLUBANdYe2EMVvoJElSQQa6wtqZ9MlzdaBzYmFJkrRwBrrC+k0sDFWX6/4DU7RzrvmSJUmSZmegK2zmLtdxEtj/oq10kiRpYQx0hbXb/btcnYtOkiQ1xUBXWL+VIuDg8l8OjJAkSQtloCus1WctV7CFTpIkNcdAV1jmy5f+AlvoJElScwx0hbVmuIfuqOXjBAY6SZK0cAa6wlrt7DvKdSzC1SIkSVIjDHSFZfZf+gucXFiSJDXDQFdYK/tPLAywcsW4LXSSJGnBDHSFzTSxMLieqyRJaoaBrrCZJhaGKtDZQidJkhbKQFfYTBMLQzUX3YGpNi+12kOulSRJGiUGusKqaUv6B7oTVy4HYM++7w2zSpIkacQY6AprJzMGutdOHkMADz3x3HArJUmSRoqBrrB2znwP3coVE5x6wlE8aKCTJEkLYKArrNWe+R46gLUnH8vuf3yB/Q6OkCRJh8lAV1jOMm0JwA+efCwJPLT3+eFVSpIkjRQDXWGtWbpcAU454SiOWjbOg/9gt6skSTo8BrrC2rOsFAHVgIm1Jx/DQ08+TztziDWTJEmjwkBXUGaSCTFLoAM48+Rjef7AFP/g9CWSJOkwGOgKatcNbrMNigBY++pjAHjAbldJknQYDHQFtepEN0ee49hXLOOMyZV87aG9zkknSZLmzUBXUOeeuNlGuXa8682nsXx8jF++dgf7XnipdNUkSdIIMdAV1Al0sw2K6HjlUct499mns/sfX+ADW7/h+q6SJGlgBrqCDna5zh3oAFaftJKPveN1/M3Ovbz3c7fx1PMHSlZPkiSNCANdQZ1BEYN0uXa899zX8Ml/+yPc9dg/8Y7f+1v+7uGnSKczkSRJsyga6CJiQ0TsjIhdEXF5n88jIq6sP787Is6aq2xEnBgRN0fEQ/XzCV2ffaTef2dEnFfy3AaxYmKMD739TM46/fiBy3zptu/wvZfa/NJbz2D/iy3e/fu38aNX3MKvXLuD/7r9fv7g/3yLL932nXKVliRJS06Uav2JiHHgQeDtwG7gDuDCzLyva5/zgV8DzgfOAX43M8+ZrWxEfAJ4JjM/Xge9EzLzwxGxDvhD4Gzg+4G/BM7MzNZMdVy/fn3u2LGj8XPv53BC2IGpFt/cvY87v/2PfPuZ/QAEsOqVr+Dd55zOhtevYs1JK+ecFkWSJC19EXFnZq7v99lEwe89G9iVmY/UldgKbALu69pnE3BtVqny1og4PiJWAatnKbsJ+PG6/OeBvwE+XG/fmpkHgEcjYlddh68XPMeiVkyMs371iaxffSL7XniJx//pBR7/pxd46Mnn+Z2bHuR3bnqQCDjuFcs44ehlnLByOSccvZxjVkywcsUEK5ePc/SKCY5ZMc7RyydYuWKco5ZNMDEWjI8FY2PBeARjYzAxNsb4WHW/3/hYTD9PdO3XKTPR9XmnfKdMBARVwKxeU7+OrtdzT7YsSZIGVzLQnQI81vV+N1Ur3Fz7nDJH2ZMzcw9AZu6JiFd3HevWPscaCa88ahmvPGoZP7zqOH7yh09m3wsvsfMfnuPZ773E/hen+O6BFs+9MMUT+77H96bavNh5LIHRsrMGPwYIfs3swlwZc5C6mFOlf3782QvgrWsn2fILb1607y8Z6Pr9M97bvzvTPoOUPZzvIyI2A5vrt89HxM45jtuUk4CnhvRdmpnX4cjgdThyeC2ODF6HI8NhX4f7gM9e1Gxl+njNTB+UDHS7gdO63p8KPD7gPstnKftERKyqW+dWAU/O4/vIzKuBq+d3KgsXETtm6vfW8HgdjgxehyOH1+LI4HU4Mizl61BylOsdwNqIWBMRy4ELgG09+2wDLqpHu54L7Ku7U2cruw14X/36fcCfdW2/ICJWRMQaYC1we6mTkyRJOlIUa6HLzKmIuAy4ERgHrsnMeyPikvrzLcB2qhGuu4D9wMWzla0P/XHguoh4P/Ad4F11mXsj4jqqVs8p4NLZRrhKkiSNimLTluhQEbG57u7VIvI6HBm8DkcOr8WRwetwZFjK18FAJ0mStMS59JckSdISZ6ArbK7lz7RwEfGtiPhmRNwVETvqbfNeIi4i3lwfZ1e9JJ3TS80hIq6JiCcj4p6ubY397etBTn9Ub78tIlYP9QSXiBmuw8ci4v/Vv4u76pV5Op95HQqIiNMi4q8j4v6IuDciPlBv9zcxRLNch9H+TWSmj0IPqgEdDwNnUE3F8vfAusWu16g9gG8BJ/Vs+wRwef36cuC/1a/X1ddhBbCmvj7j9We3Az9GNafhV4CNi31uR/oDeBtwFnBPib898KvAlvr1BcAfLfY5H4mPGa7Dx4D/0Gdfr0O567AKOKt+fSzVEpbr/E0cMddhpH8TttCVNb38WWa+CHSWMFN5m6iWhqN+/pmu7Vsz80BmPko1wvrsqOY0PC4zv57VL/TarjKaQWZ+DXimZ3OTf/vuY/0J8JO2nL7cDNdhJl6HQjJzT2b+3/r1c8D9VCsW+ZsYolmuw0xG4joY6MqaaWkzNSuBmyLizqhWAoGeJeKA7iXiZlpubnef7Zq/Jv/202UycwrYB7yqWM1Hz2URcXfdJdvp5vM6DEHdBfcm4Db8TSyanusAI/ybMNCVdThLmGn+3pKZZwEbgUsj4m2z7NvkcnOan8P523tdDt9VwGuBNwJ7gP9eb/c6FBYRxwDXAx/MzGdn27XPNq9FQ/pch5H+TRjoyhpoOTItTGY+Xj8/CdxA1dX9RN1cTgy2RNzu+nXvds1fk3/76TIRMQG8ksG7Fv9Zy8wnMrOVmW3g96l+F+B1KCoillGFiC9m5p/Wm/1NDFm/6zDqvwkDXVmDLH+mBYiIlRFxbOc18FPAPcxzibi6G+S5iDi3vg/ioq4ymp8m//bdx/p54K/qe1k0h06AqL2T6ncBXodi6r/b/wDuz8xPdn3kb2KIZroOI/+bWOxRGaP+oFra7EGqUTMfXez6jNqDagTx39ePezt/Y6p7GW4BHqqfT+wq89H6euykayQrsJ7qB/4w8Cnqibd9zPr3/0OqrouXqP6P9f1N/u2BVwB/THWT8u3AGYt9zkfiY4br8AXgm8DdVP/xWeV1KH4d/iVVt9vdwF3143x/E0fMdRjp34QrRUiSJC1xdrlKkiQtcQY6SZKkJc5AJ0mStMQZ6CRJkpY4A50kSdISZ6CTpC4R8c6IyIj4oUWswwcj4ujF+n5JS4+BTpIOdSHwt1QTgS+WDwIGOkkDM9BJUq1e+/EtVBPzXlBv+/GI+GpEXBcRD0bExyPiPRFxe0R8MyJeW+/3moi4pV74+5aIOL3e/gcR8fNd3/F813H/JiL+JCIeiIgvRuXXge8H/joi/nrIfwJJS5SBTpIO+hngf2fmg8AzEXFWvf1HgA8A/wL4BeDMzDwb+Bzwa/U+nwKuzcw3AF8Erhzg+95E1Rq3jmrVk7dk5pVU60X+RGb+RBMnJWn0Gegk6aALga316631e4A7MnNPZh6gWgLopnr7N4HV9esfA75Uv/4C1fJDc7k9M3dntVj4XV3HkqR5mVjsCkjSkSAiXgX8a+D1EZHAONV6kNuBA127trvet5n536OddRWnqP/nuV7ge3nXPt3Hbc1yLEmalS10klT5eaou09dk5urMPA14lMFa2gD+joMDKd5DNbAC4FvAm+vXm4BlAxzrOeDYAb9Xkgx0klS7ELihZ9v1wLsHLP/rwMURcTfVfXYfqLf/PvCvIuJ24BzguwMc62rgKw6KkDSoyMy595IkSdIRyxY6SZKkJc5AJ0mStMQZ6CRJkpY4A50kSdISZ6CTJEla4gx0kiRJS5yBTpIkaYkz0EmSJC1x/x+bUC62OTNUZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.distplot(df.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e71c7a",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6c466990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df = df.drop(['Amount'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a58551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "x = df.drop(['Class'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b1a54",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4728ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 44.0160 - accuracy: 0.9556 - val_loss: 4.2899 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 861us/step - loss: 18.9315 - accuracy: 0.9978 - val_loss: 3.9707 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 790us/step - loss: 18.4492 - accuracy: 0.9977 - val_loss: 3.4789 - val_accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 791us/step - loss: 15.7102 - accuracy: 0.9977 - val_loss: 2.8993 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 808us/step - loss: 9.0592 - accuracy: 0.9982 - val_loss: 2.2563 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 794us/step - loss: 6.5583 - accuracy: 0.9983 - val_loss: 1.5405 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 786us/step - loss: 4.6175 - accuracy: 0.9983 - val_loss: 0.8316 - val_accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 803us/step - loss: 2.3335 - accuracy: 0.9977 - val_loss: 0.0043 - val_accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 802us/step - loss: 15.6767 - accuracy: 0.9544 - val_loss: 6.9893 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 787us/step - loss: 23.9371 - accuracy: 0.9980 - val_loss: 6.1210 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b5262220>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x, y, validation_split = 0.2, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22fb11c",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, split (O), sampling(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29f4843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df = df.drop(['Amount'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a4ccf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "x = df.drop(['Class'], axis = 1, inplace = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf6553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "485/485 [==============================] - 0s 673us/step - loss: 225.4220 - accuracy: 0.9316 - val_loss: 6.1760 - val_accuracy: 0.9981\n",
      "Epoch 2/10\n",
      "485/485 [==============================] - 0s 520us/step - loss: 2.8849 - accuracy: 0.9972 - val_loss: 0.0427 - val_accuracy: 0.9953\n",
      "Epoch 3/10\n",
      "485/485 [==============================] - 0s 569us/step - loss: 10.5109 - accuracy: 0.9888 - val_loss: 0.1034 - val_accuracy: 0.9960\n",
      "Epoch 4/10\n",
      "485/485 [==============================] - 0s 536us/step - loss: 4.2534 - accuracy: 0.9939 - val_loss: 16.9325 - val_accuracy: 0.9982\n",
      "Epoch 5/10\n",
      "485/485 [==============================] - 0s 556us/step - loss: 11.5087 - accuracy: 0.9982 - val_loss: 0.0889 - val_accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "485/485 [==============================] - 0s 546us/step - loss: 1.0942 - accuracy: 0.9951 - val_loss: 0.2085 - val_accuracy: 0.9975\n",
      "Epoch 7/10\n",
      "485/485 [==============================] - 0s 547us/step - loss: 1.3042 - accuracy: 0.9962 - val_loss: 22.3260 - val_accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "485/485 [==============================] - 0s 544us/step - loss: 14.7938 - accuracy: 0.9984 - val_loss: 2.6823 - val_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "485/485 [==============================] - 0s 519us/step - loss: 0.5478 - accuracy: 0.9966 - val_loss: 0.0995 - val_accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "485/485 [==============================] - 0s 575us/step - loss: 0.6902 - accuracy: 0.9970 - val_loss: 0.2517 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17f96a1f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x_train, y_train, validation_split = 0.2, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc7ad9",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, split (O), sampling(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69928caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df = df.drop(['Amount'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "87ecdc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28481, 31)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = df.sample(frac = 0.1, random_state = 10 )\n",
    "df_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f737c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_pre['Class']\n",
    "x = df_pre.drop(['Class'], axis = 1, inplace = False)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "763dcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 33.5167 - accuracy: 0.9180 - val_loss: 1.0342 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 850us/step - loss: 4.1473 - accuracy: 0.9978 - val_loss: 0.8634 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 791us/step - loss: 3.8456 - accuracy: 0.9977 - val_loss: 0.6266 - val_accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 808us/step - loss: 1.5475 - accuracy: 0.9985 - val_loss: 0.3522 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 821us/step - loss: 1.0422 - accuracy: 0.9983 - val_loss: 0.0508 - val_accuracy: 0.9988\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 810us/step - loss: 0.1301 - accuracy: 0.9950 - val_loss: 0.0095 - val_accuracy: 0.9961\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 784us/step - loss: 0.0607 - accuracy: 0.9937 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 803us/step - loss: 0.0760 - accuracy: 0.9967 - val_loss: 0.0090 - val_accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 807us/step - loss: 0.1292 - accuracy: 0.9964 - val_loss: 1.2216 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 793us/step - loss: 6.3445 - accuracy: 0.9976 - val_loss: 1.0765 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x297a9b2e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x, y, validation_split = 0.2, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18979721",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, split (X), sampling(n / 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35fc1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df = df.drop(['Amount'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c25c282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df.Class, hue=df.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "352d3195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142905</th>\n",
       "      <td>85008.0</td>\n",
       "      <td>-0.341475</td>\n",
       "      <td>0.900211</td>\n",
       "      <td>0.331773</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>3.184109</td>\n",
       "      <td>3.824945</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.577237</td>\n",
       "      <td>-0.819912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030354</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>-0.281175</td>\n",
       "      <td>0.901199</td>\n",
       "      <td>-0.396459</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.266486</td>\n",
       "      <td>-0.266440</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266742</th>\n",
       "      <td>162471.0</td>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.250632</td>\n",
       "      <td>-0.146602</td>\n",
       "      <td>-0.603377</td>\n",
       "      <td>-0.289108</td>\n",
       "      <td>0.867031</td>\n",
       "      <td>-0.716845</td>\n",
       "      <td>0.916121</td>\n",
       "      <td>0.761860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301229</td>\n",
       "      <td>0.682096</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>-0.396272</td>\n",
       "      <td>-1.105012</td>\n",
       "      <td>0.357460</td>\n",
       "      <td>-0.058522</td>\n",
       "      <td>-0.011369</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135785</th>\n",
       "      <td>81398.0</td>\n",
       "      <td>-0.510727</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>1.619260</td>\n",
       "      <td>-0.063728</td>\n",
       "      <td>-0.287118</td>\n",
       "      <td>-0.758775</td>\n",
       "      <td>0.451503</td>\n",
       "      <td>0.193062</td>\n",
       "      <td>-0.337795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180919</td>\n",
       "      <td>-0.626206</td>\n",
       "      <td>0.039477</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>-0.320913</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.243857</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284703</th>\n",
       "      <td>172699.0</td>\n",
       "      <td>1.019594</td>\n",
       "      <td>-1.956473</td>\n",
       "      <td>-1.431268</td>\n",
       "      <td>0.539727</td>\n",
       "      <td>-0.499995</td>\n",
       "      <td>0.301251</td>\n",
       "      <td>0.326079</td>\n",
       "      <td>-0.062475</td>\n",
       "      <td>1.121288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081894</td>\n",
       "      <td>-1.202749</td>\n",
       "      <td>-0.182683</td>\n",
       "      <td>-1.075679</td>\n",
       "      <td>-0.417648</td>\n",
       "      <td>-1.080842</td>\n",
       "      <td>-0.049144</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0</td>\n",
       "      <td>1.733372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49532</th>\n",
       "      <td>44103.0</td>\n",
       "      <td>1.104568</td>\n",
       "      <td>-0.074271</td>\n",
       "      <td>0.268681</td>\n",
       "      <td>0.566325</td>\n",
       "      <td>-0.405835</td>\n",
       "      <td>-0.423311</td>\n",
       "      <td>-0.076164</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>-0.035610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094905</td>\n",
       "      <td>0.156076</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>0.223221</td>\n",
       "      <td>0.333878</td>\n",
       "      <td>0.398708</td>\n",
       "      <td>-0.045004</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.199623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623        472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "142905   85008.0 -0.341475  0.900211  0.331773  0.813116  3.184109  3.824945   \n",
       "266742  162471.0  0.051338  0.250632 -0.146602 -0.603377 -0.289108  0.867031   \n",
       "135785   81398.0 -0.510727  0.784119  1.619260 -0.063728 -0.287118 -0.758775   \n",
       "284703  172699.0  1.019594 -1.956473 -1.431268  0.539727 -0.499995  0.301251   \n",
       "49532    44103.0  1.104568 -0.074271  0.268681  0.566325 -0.405835 -0.423311   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "142905  0.221303  0.577237 -0.819912  ...  0.030354  0.229812 -0.281175   \n",
       "266742 -0.716845  0.916121  0.761860  ...  0.301229  0.682096  0.262251   \n",
       "135785  0.451503  0.193062 -0.337795  ... -0.180919 -0.626206  0.039477   \n",
       "284703  0.326079 -0.062475  1.121288  ... -0.081894 -1.202749 -0.182683   \n",
       "49532  -0.076164  0.094704 -0.035610  ...  0.094905  0.156076 -0.034111   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Class  normal_Amount  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276      1      -0.353229  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764      1       1.761758  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029      1       0.606031  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573      1      -0.117342  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793      1      -0.349231  \n",
       "...          ...       ...       ...       ...       ...    ...            ...  \n",
       "142905  0.901199 -0.396459 -0.097724 -0.266486 -0.266440      0      -0.350191  \n",
       "266742 -0.396272 -1.105012  0.357460 -0.058522 -0.011369      0      -0.065367  \n",
       "135785  0.455717 -0.320913  0.048237  0.243857  0.109477      0      -0.317287  \n",
       "284703 -1.075679 -0.417648 -1.080842 -0.049144  0.039078      0       1.733372  \n",
       "49532   0.223221  0.333878  0.398708 -0.045004  0.000546      0      -0.199623  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=492, random_state=10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1158ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6498e9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 13.4200 - accuracy: 0.9763 - val_loss: 1.9198 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 851us/step - loss: 6.9315 - accuracy: 0.9980 - val_loss: 1.6683 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 811us/step - loss: 5.3173 - accuracy: 0.9982 - val_loss: 1.2233 - val_accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 840us/step - loss: 3.3067 - accuracy: 0.9982 - val_loss: 0.7283 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 814us/step - loss: 2.5141 - accuracy: 0.9978 - val_loss: 0.1533 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 794us/step - loss: 1.1476 - accuracy: 0.9964 - val_loss: 0.9590 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 809us/step - loss: 3.6208 - accuracy: 0.9977 - val_loss: 0.2668 - val_accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 808us/step - loss: 1.8659 - accuracy: 0.9880 - val_loss: 5.1878 - val_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 816us/step - loss: 18.6684 - accuracy: 0.9978 - val_loss: 5.0141 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 816us/step - loss: 15.0000 - accuracy: 0.9983 - val_loss: 4.4174 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d843250>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x, y, validation_split = 0.2, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f9ed0",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, split (X), sampling(n / 3:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdba6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df = df.drop(['Amount'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9dcecac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82348</th>\n",
       "      <td>59367.0</td>\n",
       "      <td>1.192189</td>\n",
       "      <td>-0.063020</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>0.048602</td>\n",
       "      <td>-0.576313</td>\n",
       "      <td>-1.146488</td>\n",
       "      <td>0.121625</td>\n",
       "      <td>-0.078745</td>\n",
       "      <td>-0.049724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385714</td>\n",
       "      <td>-1.355440</td>\n",
       "      <td>0.222594</td>\n",
       "      <td>0.504134</td>\n",
       "      <td>-0.032130</td>\n",
       "      <td>0.595740</td>\n",
       "      <td>-0.122185</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168613</th>\n",
       "      <td>119308.0</td>\n",
       "      <td>-1.197471</td>\n",
       "      <td>1.388525</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>-0.922353</td>\n",
       "      <td>-0.130133</td>\n",
       "      <td>-0.381091</td>\n",
       "      <td>-0.076796</td>\n",
       "      <td>0.482383</td>\n",
       "      <td>0.892307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161912</td>\n",
       "      <td>-0.779128</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.495131</td>\n",
       "      <td>-0.231955</td>\n",
       "      <td>-0.340336</td>\n",
       "      <td>-0.544392</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.344314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>9164.0</td>\n",
       "      <td>1.266916</td>\n",
       "      <td>-0.227154</td>\n",
       "      <td>-0.283104</td>\n",
       "      <td>-0.396024</td>\n",
       "      <td>1.536413</td>\n",
       "      <td>3.735560</td>\n",
       "      <td>-1.267179</td>\n",
       "      <td>0.924951</td>\n",
       "      <td>1.751111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133468</td>\n",
       "      <td>-0.252073</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.978280</td>\n",
       "      <td>0.303960</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>-0.023538</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.320685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67891</th>\n",
       "      <td>52740.0</td>\n",
       "      <td>-1.792495</td>\n",
       "      <td>1.881797</td>\n",
       "      <td>0.580080</td>\n",
       "      <td>1.070823</td>\n",
       "      <td>-0.852380</td>\n",
       "      <td>-0.013791</td>\n",
       "      <td>-0.523862</td>\n",
       "      <td>1.327319</td>\n",
       "      <td>-0.602669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.123419</td>\n",
       "      <td>0.056480</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>-0.126013</td>\n",
       "      <td>-0.466111</td>\n",
       "      <td>-0.208815</td>\n",
       "      <td>-0.003144</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.304493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260308</th>\n",
       "      <td>159490.0</td>\n",
       "      <td>-0.078265</td>\n",
       "      <td>0.466851</td>\n",
       "      <td>0.109917</td>\n",
       "      <td>-0.890981</td>\n",
       "      <td>0.085511</td>\n",
       "      <td>-0.164009</td>\n",
       "      <td>1.154711</td>\n",
       "      <td>-0.120082</td>\n",
       "      <td>0.219301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054915</td>\n",
       "      <td>-0.036349</td>\n",
       "      <td>-0.025421</td>\n",
       "      <td>-0.399846</td>\n",
       "      <td>-0.295689</td>\n",
       "      <td>-0.169267</td>\n",
       "      <td>-0.050250</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1971 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623        472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "82348    59367.0  1.192189 -0.063020  0.130224  0.048602 -0.576313 -1.146488   \n",
       "168613  119308.0 -1.197471  1.388525  0.215220 -0.922353 -0.130133 -0.381091   \n",
       "7001      9164.0  1.266916 -0.227154 -0.283104 -0.396024  1.536413  3.735560   \n",
       "67891    52740.0 -1.792495  1.881797  0.580080  1.070823 -0.852380 -0.013791   \n",
       "260308  159490.0 -0.078265  0.466851  0.109917 -0.890981  0.085511 -0.164009   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "82348   0.121625 -0.078745 -0.049724  ... -0.385714 -1.355440  0.222594   \n",
       "168613 -0.076796  0.482383  0.892307  ... -0.161912 -0.779128  0.090628   \n",
       "7001   -1.267179  0.924951  1.751111  ... -0.133468 -0.252073  0.004096   \n",
       "67891  -0.523862  1.327319 -0.602669  ...  0.002532 -0.123419  0.056480   \n",
       "260308  1.154711 -0.120082  0.219301  ... -0.054915 -0.036349 -0.025421   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Class  normal_Amount  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276      1      -0.353229  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764      1       1.761758  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029      1       0.606031  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573      1      -0.117342  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793      1      -0.349231  \n",
       "...          ...       ...       ...       ...       ...    ...            ...  \n",
       "82348   0.504134 -0.032130  0.595740 -0.122185 -0.004030      0      -0.221333  \n",
       "168613  0.495131 -0.231955 -0.340336 -0.544392  0.054976      0      -0.344314  \n",
       "7001    0.978280  0.303960  0.432750 -0.023538  0.015141      0      -0.320685  \n",
       "67891   0.094167 -0.126013 -0.466111 -0.208815 -0.003144      0      -0.304493  \n",
       "260308 -0.399846 -0.295689 -0.169267 -0.050250 -0.002326      0       0.062652  \n",
       "\n",
       "[1971 rows x 31 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=1479, random_state=10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d7205fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b11e1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y_1, test_size = 0.15, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "43f75e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3425.5872 - accuracy: 0.3072 - val_loss: 1854.7664 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 775.3859 - accuracy: 0.4057 - val_loss: 3.9535e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 508.6896 - accuracy: 0.6762 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 676.7169 - accuracy: 0.6893 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 551.3305 - accuracy: 0.6825 - val_loss: 8.2769e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 215.9815 - accuracy: 0.6544 - val_loss: 309.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 181.6439 - accuracy: 0.3641 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 73.6131 - accuracy: 0.6845 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 55.6893 - accuracy: 0.5872 - val_loss: 10.2540 - val_accuracy: 0.0051\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 57.8759 - accuracy: 0.4928 - val_loss: 5.1967e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1681ea670>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x_1, y_1, validation_split = 0.2, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d20a8f",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, normal_time, split (X), sampling(n / 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c09e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "      <th>normal_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-1.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>-1.986644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>-1.902623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>-1.849472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.838248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142905</th>\n",
       "      <td>-0.341475</td>\n",
       "      <td>0.900211</td>\n",
       "      <td>0.331773</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>3.184109</td>\n",
       "      <td>3.824945</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.577237</td>\n",
       "      <td>-0.819912</td>\n",
       "      <td>0.411051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>-0.281175</td>\n",
       "      <td>0.901199</td>\n",
       "      <td>-0.396459</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.266486</td>\n",
       "      <td>-0.266440</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350191</td>\n",
       "      <td>-0.206491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266742</th>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.250632</td>\n",
       "      <td>-0.146602</td>\n",
       "      <td>-0.603377</td>\n",
       "      <td>-0.289108</td>\n",
       "      <td>0.867031</td>\n",
       "      <td>-0.716845</td>\n",
       "      <td>0.916121</td>\n",
       "      <td>0.761860</td>\n",
       "      <td>-1.107982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682096</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>-0.396272</td>\n",
       "      <td>-1.105012</td>\n",
       "      <td>0.357460</td>\n",
       "      <td>-0.058522</td>\n",
       "      <td>-0.011369</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065367</td>\n",
       "      <td>1.424719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135785</th>\n",
       "      <td>-0.510727</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>1.619260</td>\n",
       "      <td>-0.063728</td>\n",
       "      <td>-0.287118</td>\n",
       "      <td>-0.758775</td>\n",
       "      <td>0.451503</td>\n",
       "      <td>0.193062</td>\n",
       "      <td>-0.337795</td>\n",
       "      <td>-0.081085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626206</td>\n",
       "      <td>0.039477</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>-0.320913</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.243857</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317287</td>\n",
       "      <td>-0.282510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284703</th>\n",
       "      <td>1.019594</td>\n",
       "      <td>-1.956473</td>\n",
       "      <td>-1.431268</td>\n",
       "      <td>0.539727</td>\n",
       "      <td>-0.499995</td>\n",
       "      <td>0.301251</td>\n",
       "      <td>0.326079</td>\n",
       "      <td>-0.062475</td>\n",
       "      <td>1.121288</td>\n",
       "      <td>-0.403165</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.202749</td>\n",
       "      <td>-0.182683</td>\n",
       "      <td>-1.075679</td>\n",
       "      <td>-0.417648</td>\n",
       "      <td>-1.080842</td>\n",
       "      <td>-0.049144</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0</td>\n",
       "      <td>1.733372</td>\n",
       "      <td>1.640099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49532</th>\n",
       "      <td>1.104568</td>\n",
       "      <td>-0.074271</td>\n",
       "      <td>0.268681</td>\n",
       "      <td>0.566325</td>\n",
       "      <td>-0.405835</td>\n",
       "      <td>-0.423311</td>\n",
       "      <td>-0.076164</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>-0.035610</td>\n",
       "      <td>0.128550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156076</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>0.223221</td>\n",
       "      <td>0.333878</td>\n",
       "      <td>0.398708</td>\n",
       "      <td>-0.045004</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.199623</td>\n",
       "      <td>-1.067865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "142905 -0.341475  0.900211  0.331773  0.813116  3.184109  3.824945  0.221303   \n",
       "266742  0.051338  0.250632 -0.146602 -0.603377 -0.289108  0.867031 -0.716845   \n",
       "135785 -0.510727  0.784119  1.619260 -0.063728 -0.287118 -0.758775  0.451503   \n",
       "284703  1.019594 -1.956473 -1.431268  0.539727 -0.499995  0.301251  0.326079   \n",
       "49532   1.104568 -0.074271  0.268681  0.566325 -0.405835 -0.423311 -0.076164   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "541     1.391657 -2.770089 -2.772272  ... -0.035049 -0.465211  0.320198   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.435477  1.375966 -0.293803   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.932391  0.172726 -0.087330   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.176968 -0.436207 -0.053502   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.704181 -0.656805 -1.632653   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "142905  0.577237 -0.819912  0.411051  ...  0.229812 -0.281175  0.901199   \n",
       "266742  0.916121  0.761860 -1.107982  ...  0.682096  0.262251 -0.396272   \n",
       "135785  0.193062 -0.337795 -0.081085  ... -0.626206  0.039477  0.455717   \n",
       "284703 -0.062475  1.121288 -0.403165  ... -1.202749 -0.182683 -1.075679   \n",
       "49532   0.094704 -0.035610  0.128550  ...  0.156076 -0.034111  0.223221   \n",
       "\n",
       "             V25       V26       V27       V28  Class  normal_Amount  \\\n",
       "541     0.044519  0.177840  0.261145 -0.143276      1      -0.353229   \n",
       "623     0.279798 -0.145362 -0.252773  0.035764      1       1.761758   \n",
       "4920   -0.156114 -0.542628  0.039566 -0.153029      1       0.606031   \n",
       "6108    0.252405 -0.657488 -0.827136  0.849573      1      -0.117342   \n",
       "6329    1.488901  0.566797 -0.010016  0.146793      1      -0.349231   \n",
       "...          ...       ...       ...       ...    ...            ...   \n",
       "142905 -0.396459 -0.097724 -0.266486 -0.266440      0      -0.350191   \n",
       "266742 -1.105012  0.357460 -0.058522 -0.011369      0      -0.065367   \n",
       "135785 -0.320913  0.048237  0.243857  0.109477      0      -0.317287   \n",
       "284703 -0.417648 -1.080842 -0.049144  0.039078      0       1.733372   \n",
       "49532   0.333878  0.398708 -0.045004  0.000546      0      -0.199623   \n",
       "\n",
       "        normal_Time  \n",
       "541       -1.988034  \n",
       "623       -1.986644  \n",
       "4920      -1.902623  \n",
       "6108      -1.849472  \n",
       "6329      -1.838248  \n",
       "...             ...  \n",
       "142905    -0.206491  \n",
       "266742     1.424719  \n",
       "135785    -0.282510  \n",
       "284703     1.640099  \n",
       "49532     -1.067865  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df['normal_Time'] = scale(df['Time'])\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=492, random_state=10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2e0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f62c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ba9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/Users/jjink/Desktop/python/model/'\n",
    "if not os.path.exists(MODEL_DIR) :\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = '/Users/jjink/Desktop/python/model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only = True) # verbose = 1 진행과정 막대기 출력\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9259811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5079 - val_loss: 0.7193 - val_accuracy: 0.2525\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71928, saving model to /Users/jjink/Desktop/python/model/01-0.7193.hdf5\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 0s 954us/step - loss: 0.5251 - accuracy: 0.6262 - val_loss: 0.7117 - val_accuracy: 0.4848\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71928 to 0.71166, saving model to /Users/jjink/Desktop/python/model/02-0.7117.hdf5\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 0s 921us/step - loss: 0.4280 - accuracy: 0.7720 - val_loss: 0.6489 - val_accuracy: 0.7273\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71166 to 0.64885, saving model to /Users/jjink/Desktop/python/model/03-0.6489.hdf5\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 0s 887us/step - loss: 0.3793 - accuracy: 0.8655 - val_loss: 0.5713 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64885 to 0.57134, saving model to /Users/jjink/Desktop/python/model/04-0.5713.hdf5\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 0s 881us/step - loss: 0.3248 - accuracy: 0.9172 - val_loss: 0.4857 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57134 to 0.48574, saving model to /Users/jjink/Desktop/python/model/05-0.4857.hdf5\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 0s 881us/step - loss: 0.2855 - accuracy: 0.9256 - val_loss: 0.3947 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48574 to 0.39468, saving model to /Users/jjink/Desktop/python/model/06-0.3947.hdf5\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 0s 886us/step - loss: 0.2418 - accuracy: 0.9370 - val_loss: 0.3115 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39468 to 0.31150, saving model to /Users/jjink/Desktop/python/model/07-0.3115.hdf5\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 0s 884us/step - loss: 0.2064 - accuracy: 0.9347 - val_loss: 0.2447 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31150 to 0.24469, saving model to /Users/jjink/Desktop/python/model/08-0.2447.hdf5\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 0s 920us/step - loss: 0.1764 - accuracy: 0.9475 - val_loss: 0.2016 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24469 to 0.20156, saving model to /Users/jjink/Desktop/python/model/09-0.2016.hdf5\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 0s 914us/step - loss: 0.1464 - accuracy: 0.9489 - val_loss: 0.1698 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20156 to 0.16982, saving model to /Users/jjink/Desktop/python/model/10-0.1698.hdf5\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 0s 875us/step - loss: 0.1504 - accuracy: 0.9480 - val_loss: 0.1516 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.16982 to 0.15163, saving model to /Users/jjink/Desktop/python/model/11-0.1516.hdf5\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 0s 880us/step - loss: 0.1383 - accuracy: 0.9522 - val_loss: 0.1350 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15163 to 0.13505, saving model to /Users/jjink/Desktop/python/model/12-0.1350.hdf5\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 0s 880us/step - loss: 0.1326 - accuracy: 0.9480 - val_loss: 0.1189 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.13505 to 0.11894, saving model to /Users/jjink/Desktop/python/model/13-0.1189.hdf5\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 0s 873us/step - loss: 0.1220 - accuracy: 0.9575 - val_loss: 0.1230 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11894\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 0s 898us/step - loss: 0.1007 - accuracy: 0.9696 - val_loss: 0.1205 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.11894\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 0s 930us/step - loss: 0.1256 - accuracy: 0.9552 - val_loss: 0.1181 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.11894 to 0.11814, saving model to /Users/jjink/Desktop/python/model/16-0.1181.hdf5\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 0s 927us/step - loss: 0.1017 - accuracy: 0.9593 - val_loss: 0.1141 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.11814 to 0.11406, saving model to /Users/jjink/Desktop/python/model/17-0.1141.hdf5\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 0s 902us/step - loss: 0.0914 - accuracy: 0.9697 - val_loss: 0.1121 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.11406 to 0.11210, saving model to /Users/jjink/Desktop/python/model/18-0.1121.hdf5\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 0s 900us/step - loss: 0.1241 - accuracy: 0.9529 - val_loss: 0.1159 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.11210\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 0s 914us/step - loss: 0.0776 - accuracy: 0.9734 - val_loss: 0.1163 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.11210\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 0s 884us/step - loss: 0.0941 - accuracy: 0.9721 - val_loss: 0.1138 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11210\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 0s 962us/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: 0.1161 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11210\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9797 - val_loss: 0.1112 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11210 to 0.11124, saving model to /Users/jjink/Desktop/python/model/23-0.1112.hdf5\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9721 - val_loss: 0.1151 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11124\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9787 - val_loss: 0.1148 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11124\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 0s 898us/step - loss: 0.0709 - accuracy: 0.9687 - val_loss: 0.1144 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11124\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 0s 900us/step - loss: 0.0580 - accuracy: 0.9829 - val_loss: 0.1119 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11124\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 0s 933us/step - loss: 0.0486 - accuracy: 0.9882 - val_loss: 0.1191 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11124\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 0s 938us/step - loss: 0.0752 - accuracy: 0.9755 - val_loss: 0.1125 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11124\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 0s 862us/step - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.1111 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11124 to 0.11110, saving model to /Users/jjink/Desktop/python/model/30-0.1111.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_1,y_1, validation_split = 0.1, epochs = 30, batch_size = 30, callbacks = [checkpointer,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d110236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, 'o', c = 'red', markersize = 3)\n",
    "plt.plot(x_len, y_acc, 'o', c = 'blue', markersize = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b862bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "\n",
      "\n",
      "31/31 [==============================] - 0s 299us/step - loss: 0.0625 - accuracy: 0.9807\n",
      "[0.06252910196781158, 0.9806910753250122]\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.models.load_model('/Users/jjink/Desktop/python/model/30-0.1111.hdf5')\n",
    "pred = model_1.predict(x_1)\n",
    "\n",
    "print(pred[5])\n",
    "print('\\n')\n",
    "print(model.evaluate(x_1, y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11693e3d",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, normal_time, split (X), sampling(n / 3:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0636b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "      <th>normal_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-1.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>-1.986644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>-1.902623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>-1.849472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.838248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247493</th>\n",
       "      <td>-0.466202</td>\n",
       "      <td>1.224586</td>\n",
       "      <td>-0.055462</td>\n",
       "      <td>-0.398158</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>-0.816955</td>\n",
       "      <td>1.536624</td>\n",
       "      <td>-0.540742</td>\n",
       "      <td>0.227722</td>\n",
       "      <td>-0.884476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510940</td>\n",
       "      <td>-0.331931</td>\n",
       "      <td>-0.153457</td>\n",
       "      <td>-0.180279</td>\n",
       "      <td>0.532849</td>\n",
       "      <td>-0.019341</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.113384</td>\n",
       "      <td>1.237788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>-0.366162</td>\n",
       "      <td>0.658492</td>\n",
       "      <td>0.867226</td>\n",
       "      <td>-2.202041</td>\n",
       "      <td>0.611087</td>\n",
       "      <td>-0.746637</td>\n",
       "      <td>1.092693</td>\n",
       "      <td>-0.278648</td>\n",
       "      <td>0.847974</td>\n",
       "      <td>-1.196239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585969</td>\n",
       "      <td>-0.329431</td>\n",
       "      <td>-0.417532</td>\n",
       "      <td>0.070478</td>\n",
       "      <td>-0.779169</td>\n",
       "      <td>0.255392</td>\n",
       "      <td>-0.021923</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.945623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96883</th>\n",
       "      <td>1.147861</td>\n",
       "      <td>1.261737</td>\n",
       "      <td>-1.492747</td>\n",
       "      <td>1.522315</td>\n",
       "      <td>1.047910</td>\n",
       "      <td>-1.135590</td>\n",
       "      <td>0.650327</td>\n",
       "      <td>-0.156269</td>\n",
       "      <td>-0.836451</td>\n",
       "      <td>-1.447603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180123</td>\n",
       "      <td>-0.175064</td>\n",
       "      <td>-0.080476</td>\n",
       "      <td>0.752524</td>\n",
       "      <td>-0.297092</td>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.087034</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-0.607139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82348</th>\n",
       "      <td>1.192189</td>\n",
       "      <td>-0.063020</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>0.048602</td>\n",
       "      <td>-0.576313</td>\n",
       "      <td>-1.146488</td>\n",
       "      <td>0.121625</td>\n",
       "      <td>-0.078745</td>\n",
       "      <td>-0.049724</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.355440</td>\n",
       "      <td>0.222594</td>\n",
       "      <td>0.504134</td>\n",
       "      <td>-0.032130</td>\n",
       "      <td>0.595740</td>\n",
       "      <td>-0.122185</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221333</td>\n",
       "      <td>-0.746437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168613</th>\n",
       "      <td>-1.197471</td>\n",
       "      <td>1.388525</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>-0.922353</td>\n",
       "      <td>-0.130133</td>\n",
       "      <td>-0.381091</td>\n",
       "      <td>-0.076796</td>\n",
       "      <td>0.482383</td>\n",
       "      <td>0.892307</td>\n",
       "      <td>-0.981222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779128</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.495131</td>\n",
       "      <td>-0.231955</td>\n",
       "      <td>-0.340336</td>\n",
       "      <td>-0.544392</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.344314</td>\n",
       "      <td>0.515796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1968 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "247493 -0.466202  1.224586 -0.055462 -0.398158  0.732600 -0.816955  1.536624   \n",
       "2842   -0.366162  0.658492  0.867226 -2.202041  0.611087 -0.746637  1.092693   \n",
       "96883   1.147861  1.261737 -1.492747  1.522315  1.047910 -1.135590  0.650327   \n",
       "82348   1.192189 -0.063020  0.130224  0.048602 -0.576313 -1.146488  0.121625   \n",
       "168613 -1.197471  1.388525  0.215220 -0.922353 -0.130133 -0.381091 -0.076796   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "541     1.391657 -2.770089 -2.772272  ... -0.035049 -0.465211  0.320198   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.435477  1.375966 -0.293803   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.932391  0.172726 -0.087330   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.176968 -0.436207 -0.053502   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.704181 -0.656805 -1.632653   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "247493 -0.540742  0.227722 -0.884476  ...  0.510940 -0.331931 -0.153457   \n",
       "2842   -0.278648  0.847974 -1.196239  ...  0.585969 -0.329431 -0.417532   \n",
       "96883  -0.156269 -0.836451 -1.447603  ... -0.180123 -0.175064 -0.080476   \n",
       "82348  -0.078745 -0.049724  0.077990  ... -1.355440  0.222594  0.504134   \n",
       "168613  0.482383  0.892307 -0.981222  ... -0.779128  0.090628  0.495131   \n",
       "\n",
       "             V25       V26       V27       V28  Class  normal_Amount  \\\n",
       "541     0.044519  0.177840  0.261145 -0.143276      1      -0.353229   \n",
       "623     0.279798 -0.145362 -0.252773  0.035764      1       1.761758   \n",
       "4920   -0.156114 -0.542628  0.039566 -0.153029      1       0.606031   \n",
       "6108    0.252405 -0.657488 -0.827136  0.849573      1      -0.117342   \n",
       "6329    1.488901  0.566797 -0.010016  0.146793      1      -0.349231   \n",
       "...          ...       ...       ...       ...    ...            ...   \n",
       "247493 -0.180279  0.532849 -0.019341  0.027073      0      -0.113384   \n",
       "2842    0.070478 -0.779169  0.255392 -0.021923      0      -0.349231   \n",
       "96883   0.752524 -0.297092  0.057743  0.087034      0      -0.349231   \n",
       "82348  -0.032130  0.595740 -0.122185 -0.004030      0      -0.221333   \n",
       "168613 -0.231955 -0.340336 -0.544392  0.054976      0      -0.344314   \n",
       "\n",
       "        normal_Time  \n",
       "541       -1.988034  \n",
       "623       -1.986644  \n",
       "4920      -1.902623  \n",
       "6108      -1.849472  \n",
       "6329      -1.838248  \n",
       "...             ...  \n",
       "247493     1.237788  \n",
       "2842      -1.945623  \n",
       "96883     -0.607139  \n",
       "82348     -0.746437  \n",
       "168613     0.515796  \n",
       "\n",
       "[1968 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df['normal_Time'] = scale(df['Time'])\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=1476, random_state = 10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e3d481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44e73757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12455c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/Users/jjink/Desktop/python/model/'\n",
    "if not os.path.exists(MODEL_DIR) :\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = '/Users/jjink/Desktop/python/model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 1, save_best_only = True) # verbose = 1 진행과정 막대기 출력\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c69c3c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7133 - accuracy: 0.3506 - val_loss: 0.7516 - val_accuracy: 0.3503\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75160, saving model to /Users/jjink/Desktop/python/model/01-0.7516.hdf5\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.6124 - val_loss: 0.5999 - val_accuracy: 0.7766\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75160 to 0.59993, saving model to /Users/jjink/Desktop/python/model/02-0.5999.hdf5\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.8503 - val_loss: 0.4781 - val_accuracy: 0.9594\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.59993 to 0.47812, saving model to /Users/jjink/Desktop/python/model/03-0.4781.hdf5\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.9325 - val_loss: 0.3779 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47812 to 0.37790, saving model to /Users/jjink/Desktop/python/model/04-0.3779.hdf5\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.9555 - val_loss: 0.2937 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37790 to 0.29369, saving model to /Users/jjink/Desktop/python/model/05-0.2937.hdf5\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.9550 - val_loss: 0.2242 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.29369 to 0.22416, saving model to /Users/jjink/Desktop/python/model/06-0.2242.hdf5\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9608 - val_loss: 0.1727 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.22416 to 0.17268, saving model to /Users/jjink/Desktop/python/model/07-0.1727.hdf5\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9584 - val_loss: 0.1364 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.17268 to 0.13641, saving model to /Users/jjink/Desktop/python/model/08-0.1364.hdf5\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9602 - val_loss: 0.1091 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13641 to 0.10914, saving model to /Users/jjink/Desktop/python/model/09-0.1091.hdf5\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9607 - val_loss: 0.0922 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.10914 to 0.09221, saving model to /Users/jjink/Desktop/python/model/10-0.0922.hdf5\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9652 - val_loss: 0.0795 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09221 to 0.07947, saving model to /Users/jjink/Desktop/python/model/11-0.0795.hdf5\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9675 - val_loss: 0.0725 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07947 to 0.07251, saving model to /Users/jjink/Desktop/python/model/12-0.0725.hdf5\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9665 - val_loss: 0.0676 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07251 to 0.06761, saving model to /Users/jjink/Desktop/python/model/13-0.0676.hdf5\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9661 - val_loss: 0.0642 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06761 to 0.06419, saving model to /Users/jjink/Desktop/python/model/14-0.0642.hdf5\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 0.0609 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06419 to 0.06086, saving model to /Users/jjink/Desktop/python/model/15-0.0609.hdf5\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9744 - val_loss: 0.0565 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06086 to 0.05652, saving model to /Users/jjink/Desktop/python/model/16-0.0565.hdf5\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9770 - val_loss: 0.0580 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05652\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9734 - val_loss: 0.0570 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05652\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9756 - val_loss: 0.0554 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05652 to 0.05544, saving model to /Users/jjink/Desktop/python/model/19-0.0554.hdf5\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9691 - val_loss: 0.0553 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05544 to 0.05527, saving model to /Users/jjink/Desktop/python/model/20-0.0553.hdf5\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.0553 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05527\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9758 - val_loss: 0.0563 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05527\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9706 - val_loss: 0.0556 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05527\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9763 - val_loss: 0.0543 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05527 to 0.05428, saving model to /Users/jjink/Desktop/python/model/24-0.0543.hdf5\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9737 - val_loss: 0.0558 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05428\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9735 - val_loss: 0.0584 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05428\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.0595 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05428\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9739 - val_loss: 0.0572 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05428\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9798 - val_loss: 0.0576 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05428\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.0582 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05428\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_1,y_1, validation_split = 0.1, epochs = 30, batch_size = 100, callbacks = [checkpointer,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b62af56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAARFklEQVR4nO3df4xld1nH8ffjlI0NoCAdCO5u3WqK2hBA9lKcaHR0Rbb4x4pR02LkR0zWJtTgfy0mCtq4q0aUGArNihsgURoSKqymWknjiGYH3VlS2m5rcVKgHbZhpxZ/FP/Y7Pbxj3sn3E7vj3Nm7p0z53vfr2Ry55z7nXOfs2fnM9955txzIjORJJXhO5ouQJI0OYa6JBXEUJekghjqklQQQ12SCnJFUy981VVX5YEDB5p6eUlqpbNnzz6VmfPDnm8s1A8cOMDKykpTLy9JrRQRXxv1/Nj2S0ScjIgLEfHQkOcjIv4sIlYj4oGIeP1Wi5UkbU+VnvrHgMMjnr8BuLb3cRT4yPbLkiRtxdhQz8zPA0+PGHIE+ER2fQF4SUS8clIFSpKqm8TZL3uBJ/qW13rrJEk7bBKhHgPWDbygTEQcjYiViFhZX1+fwEtLkvpNItTXgP19y/uA84MGZuaJzOxkZmd+fugZOZKkLZpEqJ8C3t47C+ZHgf/OzCcnsF1Jqmx5GY4f7z7u9DbrvPY06uw39jz1iPgksAhcFRFrwPuAFwBk5p3APcBbgFXg/4B3TadUSZOyvAxLS7C4CAsLkxnb5DaXl+HQIbh4EfbsgfvuGz5+0tus+9pVx27V2FDPzJvGPJ/AuydWkTRAaSHU5DanEUJNb3NpqTvu8uXu49LSzm2z6ri6Y7csMxv5OHjwYKpdTp/OPHas+ziJcVXHnj6deeWVmXNz3cdJjJ3lbR471h0D3cdjx4Zvs+rYprc5jX1v8hiNAqzkiGxt7DIBqq8Nv95OY8Y2jZnQLG9zcbH7773x7764OHh7dcY2vc2Fhe7/n3H/l6exzarj6o7dslGJP80PZ+rf1obZapMztqb3vbRtboyd5G9Tu2GbVU1jmzuJMTN1Q31K6vynbcOvzIZQWdtUexnqDZjGDLjpWeDGeENIata4ULenPgV1+qBVe3zT6NvV7e8tLFTrAVYdV3espPGiG/w7r9PpZBuvpz7pU8aqblOSACLibGZ2hj3vTL2GqmE9rRmwJI1jqNdQp61iUEtqgjeermGj/z03N/4cV0lqgjP1GnbkjQOStA2Gek22VSTtZrZfJKkghrokFcRQl6SCGOqSVBBDXZIKYqhLUkEMdaZ/I1hJ2ikzf576TtwIVpJ2yszP1Addz0WS2mrmQ93ruUgqycy3X7yei6SSzHyog9dzkVSOmW+/SFJJDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSpIpVCPiMMR8WhErEbEbQOe/+6I+JuI+FJEnIuId02+VEnSOGNDPSLmgDuAG4DrgJsi4rpNw94NPJyZrwUWgQ9ExJ4J1ypJGqPKTP16YDUzH8vMi8BdwJFNYxJ4cUQE8CLgaeDSRCuVJI1VJdT3Ak/0La/11vX7EPDDwHngQeA9mfns5g1FxNGIWImIlfX19S2WLEkapkqox4B1uWn5zcD9wPcCrwM+FBHf9bwvyjyRmZ3M7MzPz9csVZI0TpVQXwP29y3vozsj7/cu4O7sWgW+AvzQZEqUJFVVJdTPANdGxDW9P37eCJzaNOZx4BBARLwC+EHgsUkWKkkab+ydjzLzUkTcAtwLzAEnM/NcRNzce/5O4HbgYxHxIN12za2Z+dQU65YkDVDpdnaZeQ9wz6Z1d/Z9fh742cmWJkmqy3eUSlJBDHVJKoihLkkFaV+oLy/D8ePdR0nSc1T6Q+musbwMhw7BxYuwZw/cdx8sLDRdlSTtGu2aqS8tdQP98uXu49JS0xVJ0q7SrlBfXOzO0Ofmuo+Li01XJEm7SrvaLwsL3ZbL0lI30G29SNJztCvUoRvkhrkkDdSu9oskaSRDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6JBXEUJekghjqklQQQ12SCmKoS1JBig5176chada074JeFXk/DUmzqNiZuvfTkDSLig1176chaRYV237xfhqSZlGxoQ7eT0PS7Cm2/SJJs8hQl6SCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIJVCPSIOR8SjEbEaEbcNGbMYEfdHxLmI+KfJlilJqmLsO0ojYg64A3gTsAaciYhTmflw35iXAB8GDmfm4xHx8inVW8/ystcJkDRTqlwm4HpgNTMfA4iIu4AjwMN9Y94G3J2ZjwNk5oVJF1qb196VNIOqtF/2Ak/0La/11vV7FfDSiFiKiLMR8fZBG4qIoxGxEhEr6+vrW6u4Kq+9K2kGVQn1GLAuNy1fARwEfg54M/DbEfGq531R5onM7GRmZ35+vnaxtXjtXUkzqEr7ZQ3Y37e8Dzg/YMxTmfkt4FsR8XngtcCXJ1LlVnjtXUkzqEqonwGujYhrgK8DN9Ltoff7LPChiLgC2AO8EfjTSRa6JV57V9KMGRvqmXkpIm4B7gXmgJOZeS4ibu49f2dmPhIRfw88ADwLfDQzH5pm4ZKk54vMze3xndHpdHJlZaWR15aktoqIs5nZGfa87yiVpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFcRQl6SCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6JBXEUJekghjqklQQQx1geRmOH+8+SlKLjb3xdPGWl+HQIbh4Efbsgfvug4WFpquSpC1xpr601A30y5e7j0tLTVckSVtmqC8udmfoc3Pdx8XFpiuSpC2z/bKw0G25LC11A93Wi6QWM9ShG+SGuaQC2H6RpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFcRQl6SCGOqSVJBKoR4RhyPi0YhYjYjbRox7Q0RcjohfnFyJkqSqxoZ6RMwBdwA3ANcBN0XEdUPG/SFw76SLlCRVU2Wmfj2wmpmPZeZF4C7gyIBxvwF8Grgwwfqex5sUSdJwVa7SuBd4om95DXhj/4CI2Au8Ffhp4A3DNhQRR4GjAFdffXXdWr1JkSSNUWWmHgPW5ablDwK3ZublURvKzBOZ2cnMzvz8fMUSv82bFEnSaFVm6mvA/r7lfcD5TWM6wF0RAXAV8JaIuJSZn5lEkRs2blK0MVP3JkWS9FxVQv0McG1EXAN8HbgReFv/gMy8ZuPziPgY8LeTDnTYJTcpWl72LkmSdq2xoZ6ZlyLiFrpntcwBJzPzXETc3Hv+zinX+ByN3qTIpr6kXa7S7ewy8x7gnk3rBoZ5Zr5z+2XtUoOa+oa6pF3Ed5TWsdHUn5uzqS9pV/LG03Xsiqa+JA1nqNfVaFNfkkaz/SJJBTHUJakghrokFcRQl6SCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6JBXEUJekghjq07K8DMePdx8laYd4lcZp8A5JkhriTH0aBt0hSZJ2gKE+Dd4hSVJDbL9Mg3dIktQQQ31avEOSpAbYfpGkghjqklQQQ12SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6ruBl+mVNCFeJqBpXqZX0gQ5U2+al+mVNEGGetO8TK+kCaoU6hFxOCIejYjViLhtwPO/EhEP9D5OR8RrJ19qoTYu03v77bZeJG3b2J56RMwBdwBvAtaAMxFxKjMf7hv2FeAnM/ObEXEDcAJ44zQKLpKX6ZU0IVVm6tcDq5n5WGZeBO4CjvQPyMzTmfnN3uIXgH2TLVOSVEWVUN8LPNG3vNZbN8yvAX836ImIOBoRKxGxsr6+Xr1KSVIlVUI9BqzLgQMjfopuqN866PnMPJGZnczszM/PV69SklRJlfPU14D9fcv7gPObB0XEa4CPAjdk5n9OpjxJUh1VZupngGsj4pqI2APcCJzqHxARVwN3A7+amV+efJmSpCrGztQz81JE3ALcC8wBJzPzXETc3Hv+TuB3gJcBH44IgEuZ2Zle2TNqebn75qTFRc+WkTRQZA5sj09dp9PJlZWVRl67lbycgCQgIs6OmjT7jtK28HICkiow1NvCywlIqsCrNLbFxuUE7KlLGsFQbxMvJyBpDNsvklQQQ71U3k1Jmkm2X0rk6Y/SzHKmXiJPf5RmlqFeIk9/lGaW7ZcSefqjNLMM9VJ5+qM0k2y/zDrPkpGK4kx9lnmWjFQcZ+qzzLNkpOIY6rPMs2Sk4th+mWV1z5LxJh3Srmeoz7qqZ8nYf5dawfaLqrH/LrWCoa5q6vTfPU1SaoztF1VTtf9et01jn16aKENd1VXpvw9q00ziB4DhL1ViqGuyNto0G0E9qk1T9QeAs3+pMkNdk1XnNMmqPwB2w+y/6thpbLNppdVZ+nHPzEY+Dh48mFKePp157Fj3cdSYK6/MnJvrPo4ae+xYdxx0H48d2/42q46dxjY3xo77N6o7ts64kups03EfAljJEdnqTF3NqtKnb3r2X3XsNLZZ9zePKmPrbLO0Otty3LfBUxrVDgsL8N73Vv8BcPvto0OgzimaVcdOY5t13h9QdWydbZZWZ1uO+3aMmsZP88P2ixrXZLug6tim2wWl1VlnXNPbHIIx7Zfojtl5nU4nV1ZWGnltqVWa/sNeaXW2XESczczO0OcNdUlqj3Ghbk9dkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFaSxUxojYh342ha//CrgqQmWsxuUtk+l7Q+Ut0+l7Q+Ut0+D9uf7MnN+2Bc0FurbEREro87TbKPS9qm0/YHy9qm0/YHy9mkr+2P7RZIKYqhLUkHaGuonmi5gCkrbp9L2B8rbp9L2B8rbp9r708qeuiRpsLbO1CVJAxjqklSQ1oV6RByOiEcjYjUibmu6nkmIiK9GxIMRcX9EtO56xBFxMiIuRMRDfeu+JyI+FxH/0Xt8aZM11jVkn94fEV/vHaf7I+ItTdZYR0Tsj4h/jIhHIuJcRLynt76Vx2nE/rT5GH1nRPxbRHypt0+/21tf6xi1qqceEXPAl4E3AWvAGeCmzHy40cK2KSK+CnQys5VvmoiInwCeAT6Rma/urfsj4OnM/IPeD9+XZuatTdZZx5B9ej/wTGb+cZO1bUVEvBJ4ZWZ+MSJeDJwFfh54Jy08TiP255dp7zEK4IWZ+UxEvAD4F+A9wC9Q4xi1baZ+PbCamY9l5kXgLuBIwzXNvMz8PPD0ptVHgI/3Pv843W+41hiyT62VmU9m5hd7n/8v8Aiwl5YepxH701q9u9U901t8Qe8jqXmM2hbqe4En+pbXaPmB7EngHyLibEQcbbqYCXlFZj4J3W9A4OUN1zMpt0TEA732TCtaFZtFxAHgR4B/pYDjtGl/oMXHKCLmIuJ+4ALwucysfYzaFuoxYF17+kfD/Vhmvh64AXh371d/7T4fAX4AeB3wJPCBRqvZgoh4EfBp4Dcz83+arme7BuxPq49RZl7OzNcB+4DrI+LVdbfRtlBfA/b3Le8DzjdUy8Rk5vne4wXgr+m2mdruG72+50b/80LD9WxbZn6j9033LPDntOw49fq0nwb+MjPv7q1u7XEatD9tP0YbMvO/gCXgMDWPUdtC/QxwbURcExF7gBuBUw3XtC0R8cLeH3qIiBcCPws8NPqrWuEU8I7e5+8APttgLROx8Y3V81ZadJx6f4T7C+CRzPyTvqdaeZyG7U/Lj9F8RLyk9/mVwM8A/07NY9Sqs18AeqcofRCYA05m5u83W9H2RMT3052dA1wB/FXb9ikiPgks0r1M6DeA9wGfAT4FXA08DvxSZrbmD49D9mmR7q/1CXwV+PWNXuduFxE/Dvwz8CDwbG/1b9HtQ7fuOI3Yn5to7zF6Dd0/hM7RnXB/KjN/LyJeRo1j1LpQlyQN17b2iyRpBENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFeT/AbKat/LErZCWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, 'o', c = 'red', markersize = 3)\n",
    "plt.plot(x_len, y_acc, 'o', c = 'blue', markersize = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4162a8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "\n",
      "\n",
      "62/62 [==============================] - 0s 308us/step - loss: 0.0657 - accuracy: 0.9787\n",
      "[0.06572145223617554, 0.9786585569381714]\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.models.load_model('/Users/jjink/Desktop/python/model/24-0.0543.hdf5')\n",
    "pred = model_1.predict(x_1)\n",
    "\n",
    "print(pred[5])\n",
    "print('\\n')\n",
    "print(model.evaluate(x_1, y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51069384",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, normal_time, split (O), sampling(n / 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "25505f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "      <th>normal_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-1.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>-1.986644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>-1.902623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>-1.849472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.838248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142905</th>\n",
       "      <td>-0.341475</td>\n",
       "      <td>0.900211</td>\n",
       "      <td>0.331773</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>3.184109</td>\n",
       "      <td>3.824945</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.577237</td>\n",
       "      <td>-0.819912</td>\n",
       "      <td>0.411051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>-0.281175</td>\n",
       "      <td>0.901199</td>\n",
       "      <td>-0.396459</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.266486</td>\n",
       "      <td>-0.266440</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350191</td>\n",
       "      <td>-0.206491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266742</th>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.250632</td>\n",
       "      <td>-0.146602</td>\n",
       "      <td>-0.603377</td>\n",
       "      <td>-0.289108</td>\n",
       "      <td>0.867031</td>\n",
       "      <td>-0.716845</td>\n",
       "      <td>0.916121</td>\n",
       "      <td>0.761860</td>\n",
       "      <td>-1.107982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682096</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>-0.396272</td>\n",
       "      <td>-1.105012</td>\n",
       "      <td>0.357460</td>\n",
       "      <td>-0.058522</td>\n",
       "      <td>-0.011369</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065367</td>\n",
       "      <td>1.424719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135785</th>\n",
       "      <td>-0.510727</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>1.619260</td>\n",
       "      <td>-0.063728</td>\n",
       "      <td>-0.287118</td>\n",
       "      <td>-0.758775</td>\n",
       "      <td>0.451503</td>\n",
       "      <td>0.193062</td>\n",
       "      <td>-0.337795</td>\n",
       "      <td>-0.081085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626206</td>\n",
       "      <td>0.039477</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>-0.320913</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.243857</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317287</td>\n",
       "      <td>-0.282510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284703</th>\n",
       "      <td>1.019594</td>\n",
       "      <td>-1.956473</td>\n",
       "      <td>-1.431268</td>\n",
       "      <td>0.539727</td>\n",
       "      <td>-0.499995</td>\n",
       "      <td>0.301251</td>\n",
       "      <td>0.326079</td>\n",
       "      <td>-0.062475</td>\n",
       "      <td>1.121288</td>\n",
       "      <td>-0.403165</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.202749</td>\n",
       "      <td>-0.182683</td>\n",
       "      <td>-1.075679</td>\n",
       "      <td>-0.417648</td>\n",
       "      <td>-1.080842</td>\n",
       "      <td>-0.049144</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0</td>\n",
       "      <td>1.733372</td>\n",
       "      <td>1.640099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49532</th>\n",
       "      <td>1.104568</td>\n",
       "      <td>-0.074271</td>\n",
       "      <td>0.268681</td>\n",
       "      <td>0.566325</td>\n",
       "      <td>-0.405835</td>\n",
       "      <td>-0.423311</td>\n",
       "      <td>-0.076164</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>-0.035610</td>\n",
       "      <td>0.128550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156076</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>0.223221</td>\n",
       "      <td>0.333878</td>\n",
       "      <td>0.398708</td>\n",
       "      <td>-0.045004</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.199623</td>\n",
       "      <td>-1.067865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "142905 -0.341475  0.900211  0.331773  0.813116  3.184109  3.824945  0.221303   \n",
       "266742  0.051338  0.250632 -0.146602 -0.603377 -0.289108  0.867031 -0.716845   \n",
       "135785 -0.510727  0.784119  1.619260 -0.063728 -0.287118 -0.758775  0.451503   \n",
       "284703  1.019594 -1.956473 -1.431268  0.539727 -0.499995  0.301251  0.326079   \n",
       "49532   1.104568 -0.074271  0.268681  0.566325 -0.405835 -0.423311 -0.076164   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "541     1.391657 -2.770089 -2.772272  ... -0.035049 -0.465211  0.320198   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.435477  1.375966 -0.293803   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.932391  0.172726 -0.087330   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.176968 -0.436207 -0.053502   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.704181 -0.656805 -1.632653   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "142905  0.577237 -0.819912  0.411051  ...  0.229812 -0.281175  0.901199   \n",
       "266742  0.916121  0.761860 -1.107982  ...  0.682096  0.262251 -0.396272   \n",
       "135785  0.193062 -0.337795 -0.081085  ... -0.626206  0.039477  0.455717   \n",
       "284703 -0.062475  1.121288 -0.403165  ... -1.202749 -0.182683 -1.075679   \n",
       "49532   0.094704 -0.035610  0.128550  ...  0.156076 -0.034111  0.223221   \n",
       "\n",
       "             V25       V26       V27       V28  Class  normal_Amount  \\\n",
       "541     0.044519  0.177840  0.261145 -0.143276      1      -0.353229   \n",
       "623     0.279798 -0.145362 -0.252773  0.035764      1       1.761758   \n",
       "4920   -0.156114 -0.542628  0.039566 -0.153029      1       0.606031   \n",
       "6108    0.252405 -0.657488 -0.827136  0.849573      1      -0.117342   \n",
       "6329    1.488901  0.566797 -0.010016  0.146793      1      -0.349231   \n",
       "...          ...       ...       ...       ...    ...            ...   \n",
       "142905 -0.396459 -0.097724 -0.266486 -0.266440      0      -0.350191   \n",
       "266742 -1.105012  0.357460 -0.058522 -0.011369      0      -0.065367   \n",
       "135785 -0.320913  0.048237  0.243857  0.109477      0      -0.317287   \n",
       "284703 -0.417648 -1.080842 -0.049144  0.039078      0       1.733372   \n",
       "49532   0.333878  0.398708 -0.045004  0.000546      0      -0.199623   \n",
       "\n",
       "        normal_Time  \n",
       "541       -1.988034  \n",
       "623       -1.986644  \n",
       "4920      -1.902623  \n",
       "6108      -1.849472  \n",
       "6329      -1.838248  \n",
       "...             ...  \n",
       "142905    -0.206491  \n",
       "266742     1.424719  \n",
       "135785    -0.282510  \n",
       "284703     1.640099  \n",
       "49532     -1.067865  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df['normal_Time'] = scale(df['Time'])\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=492, random_state = 10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2cc87117",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "935eb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y_1, test_size = 0.15, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9138e415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4803 - accuracy: 0.6956 - val_loss: 0.4296 - val_accuracy: 0.7440\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4633 - accuracy: 0.7160 - val_loss: 0.4061 - val_accuracy: 0.7679\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4311 - accuracy: 0.7448 - val_loss: 0.3859 - val_accuracy: 0.7857\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4022 - accuracy: 0.7830 - val_loss: 0.3678 - val_accuracy: 0.8155\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3866 - accuracy: 0.8108 - val_loss: 0.3516 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3594 - accuracy: 0.8419 - val_loss: 0.3371 - val_accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3485 - accuracy: 0.8595 - val_loss: 0.3241 - val_accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3254 - accuracy: 0.8733 - val_loss: 0.3126 - val_accuracy: 0.8929\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3188 - accuracy: 0.8843 - val_loss: 0.3023 - val_accuracy: 0.8869\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3046 - accuracy: 0.9050 - val_loss: 0.2930 - val_accuracy: 0.8988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x295e94280>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x_train, y_train, validation_split = 0.2, epochs = 10, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6845417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 754us/step - loss: 0.2750 - accuracy: 0.9324\n",
      "[0.274978369474411, 0.9324324131011963]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bbdc42",
   "metadata": {},
   "source": [
    "## credit card - normal_amount, normal_time, split (O), sampling(n / 3:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98dad9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "      <th>normal_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-1.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>-1.986644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>-1.902623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>-1.849472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.838248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82348</th>\n",
       "      <td>1.192189</td>\n",
       "      <td>-0.063020</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>0.048602</td>\n",
       "      <td>-0.576313</td>\n",
       "      <td>-1.146488</td>\n",
       "      <td>0.121625</td>\n",
       "      <td>-0.078745</td>\n",
       "      <td>-0.049724</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.355440</td>\n",
       "      <td>0.222594</td>\n",
       "      <td>0.504134</td>\n",
       "      <td>-0.032130</td>\n",
       "      <td>0.595740</td>\n",
       "      <td>-0.122185</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221333</td>\n",
       "      <td>-0.746437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168613</th>\n",
       "      <td>-1.197471</td>\n",
       "      <td>1.388525</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>-0.922353</td>\n",
       "      <td>-0.130133</td>\n",
       "      <td>-0.381091</td>\n",
       "      <td>-0.076796</td>\n",
       "      <td>0.482383</td>\n",
       "      <td>0.892307</td>\n",
       "      <td>-0.981222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779128</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.495131</td>\n",
       "      <td>-0.231955</td>\n",
       "      <td>-0.340336</td>\n",
       "      <td>-0.544392</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.344314</td>\n",
       "      <td>0.515796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>1.266916</td>\n",
       "      <td>-0.227154</td>\n",
       "      <td>-0.283104</td>\n",
       "      <td>-0.396024</td>\n",
       "      <td>1.536413</td>\n",
       "      <td>3.735560</td>\n",
       "      <td>-1.267179</td>\n",
       "      <td>0.924951</td>\n",
       "      <td>1.751111</td>\n",
       "      <td>-0.424252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252073</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.978280</td>\n",
       "      <td>0.303960</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>-0.023538</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.320685</td>\n",
       "      <td>-1.803608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67891</th>\n",
       "      <td>-1.792495</td>\n",
       "      <td>1.881797</td>\n",
       "      <td>0.580080</td>\n",
       "      <td>1.070823</td>\n",
       "      <td>-0.852380</td>\n",
       "      <td>-0.013791</td>\n",
       "      <td>-0.523862</td>\n",
       "      <td>1.327319</td>\n",
       "      <td>-0.602669</td>\n",
       "      <td>-0.772385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123419</td>\n",
       "      <td>0.056480</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>-0.126013</td>\n",
       "      <td>-0.466111</td>\n",
       "      <td>-0.208815</td>\n",
       "      <td>-0.003144</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.304493</td>\n",
       "      <td>-0.885988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260308</th>\n",
       "      <td>-0.078265</td>\n",
       "      <td>0.466851</td>\n",
       "      <td>0.109917</td>\n",
       "      <td>-0.890981</td>\n",
       "      <td>0.085511</td>\n",
       "      <td>-0.164009</td>\n",
       "      <td>1.154711</td>\n",
       "      <td>-0.120082</td>\n",
       "      <td>0.219301</td>\n",
       "      <td>-0.683068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036349</td>\n",
       "      <td>-0.025421</td>\n",
       "      <td>-0.399846</td>\n",
       "      <td>-0.295689</td>\n",
       "      <td>-0.169267</td>\n",
       "      <td>-0.050250</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>1.361945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1971 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "82348   1.192189 -0.063020  0.130224  0.048602 -0.576313 -1.146488  0.121625   \n",
       "168613 -1.197471  1.388525  0.215220 -0.922353 -0.130133 -0.381091 -0.076796   \n",
       "7001    1.266916 -0.227154 -0.283104 -0.396024  1.536413  3.735560 -1.267179   \n",
       "67891  -1.792495  1.881797  0.580080  1.070823 -0.852380 -0.013791 -0.523862   \n",
       "260308 -0.078265  0.466851  0.109917 -0.890981  0.085511 -0.164009  1.154711   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "541     1.391657 -2.770089 -2.772272  ... -0.035049 -0.465211  0.320198   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.435477  1.375966 -0.293803   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.932391  0.172726 -0.087330   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.176968 -0.436207 -0.053502   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.704181 -0.656805 -1.632653   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "82348  -0.078745 -0.049724  0.077990  ... -1.355440  0.222594  0.504134   \n",
       "168613  0.482383  0.892307 -0.981222  ... -0.779128  0.090628  0.495131   \n",
       "7001    0.924951  1.751111 -0.424252  ... -0.252073  0.004096  0.978280   \n",
       "67891   1.327319 -0.602669 -0.772385  ... -0.123419  0.056480  0.094167   \n",
       "260308 -0.120082  0.219301 -0.683068  ... -0.036349 -0.025421 -0.399846   \n",
       "\n",
       "             V25       V26       V27       V28  Class  normal_Amount  \\\n",
       "541     0.044519  0.177840  0.261145 -0.143276      1      -0.353229   \n",
       "623     0.279798 -0.145362 -0.252773  0.035764      1       1.761758   \n",
       "4920   -0.156114 -0.542628  0.039566 -0.153029      1       0.606031   \n",
       "6108    0.252405 -0.657488 -0.827136  0.849573      1      -0.117342   \n",
       "6329    1.488901  0.566797 -0.010016  0.146793      1      -0.349231   \n",
       "...          ...       ...       ...       ...    ...            ...   \n",
       "82348  -0.032130  0.595740 -0.122185 -0.004030      0      -0.221333   \n",
       "168613 -0.231955 -0.340336 -0.544392  0.054976      0      -0.344314   \n",
       "7001    0.303960  0.432750 -0.023538  0.015141      0      -0.320685   \n",
       "67891  -0.126013 -0.466111 -0.208815 -0.003144      0      -0.304493   \n",
       "260308 -0.295689 -0.169267 -0.050250 -0.002326      0       0.062652   \n",
       "\n",
       "        normal_Time  \n",
       "541       -1.988034  \n",
       "623       -1.986644  \n",
       "4920      -1.902623  \n",
       "6108      -1.849472  \n",
       "6329      -1.838248  \n",
       "...             ...  \n",
       "82348     -0.746437  \n",
       "168613     0.515796  \n",
       "7001      -1.803608  \n",
       "67891     -0.885988  \n",
       "260308     1.361945  \n",
       "\n",
       "[1971 rows x 31 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df['normal_Time'] = scale(df['Time'])\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=1479, random_state = 10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2d42bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y_1, test_size = 0.15, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "afa651c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9662 - accuracy: 0.6500 - val_loss: 0.7405 - val_accuracy: 0.6776\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7361 - accuracy: 0.6864 - val_loss: 0.6134 - val_accuracy: 0.7582\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.7727 - val_loss: 0.5583 - val_accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.8855 - val_loss: 0.5316 - val_accuracy: 0.8866\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.8950 - val_loss: 0.5089 - val_accuracy: 0.8925\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.9076 - val_loss: 0.4868 - val_accuracy: 0.8985\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.9169 - val_loss: 0.4650 - val_accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.9263 - val_loss: 0.4430 - val_accuracy: 0.9075\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.9268 - val_loss: 0.4210 - val_accuracy: 0.9134\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.9326 - val_loss: 0.3995 - val_accuracy: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2959cab80>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x_train, y_train, validation_split = 0.2, epochs = 10, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "393d2d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 615us/step - loss: 0.3783 - accuracy: 0.9392\n",
      "[0.37833890318870544, 0.9391891956329346]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c719c",
   "metadata": {},
   "source": [
    "## credit card - minmax_amount, minmax_time, split (O), sampling(n / 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "67dff906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.6570 - val_loss: 0.2904 - val_accuracy: 0.9048\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 0s 663us/step - loss: 0.2543 - accuracy: 0.9345 - val_loss: 0.2057 - val_accuracy: 0.9464\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 0s 647us/step - loss: 0.1693 - accuracy: 0.9600 - val_loss: 0.1755 - val_accuracy: 0.9464\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 0s 648us/step - loss: 0.1269 - accuracy: 0.9691 - val_loss: 0.1623 - val_accuracy: 0.9464\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 0s 662us/step - loss: 0.1246 - accuracy: 0.9583 - val_loss: 0.1547 - val_accuracy: 0.9405\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 0s 659us/step - loss: 0.1302 - accuracy: 0.9566 - val_loss: 0.1514 - val_accuracy: 0.9405\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 0s 637us/step - loss: 0.0967 - accuracy: 0.9635 - val_loss: 0.1519 - val_accuracy: 0.9405\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 0s 627us/step - loss: 0.1001 - accuracy: 0.9618 - val_loss: 0.1528 - val_accuracy: 0.9405\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 0s 644us/step - loss: 0.0962 - accuracy: 0.9663 - val_loss: 0.1553 - val_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 0s 643us/step - loss: 0.0772 - accuracy: 0.9683 - val_loss: 0.1561 - val_accuracy: 0.9345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aa0032e0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['minmax_Amount'] = minmax_scale(df['Amount'])\n",
    "df['minmax_Time'] = minmax_scale(df['Time'])\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=492, random_state = 10)\n",
    "data = pd.concat([a, c])\n",
    "data\n",
    "\n",
    "df.head()\n",
    "\n",
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y_1, test_size = 0.15, random_state = 5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x_train, y_train, validation_split = 0.2, epochs = 10, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5def0f",
   "metadata": {},
   "source": [
    "## credit card - robust_amount, robust_time, split (O), sampling(n / 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "869ab9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8274 - val_loss: 0.3199 - val_accuracy: 0.8869\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 0s 671us/step - loss: 0.2475 - accuracy: 0.9182 - val_loss: 0.2455 - val_accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 0s 639us/step - loss: 0.1813 - accuracy: 0.9334 - val_loss: 0.2056 - val_accuracy: 0.9345\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 0s 668us/step - loss: 0.1193 - accuracy: 0.9606 - val_loss: 0.1851 - val_accuracy: 0.9226\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 0s 632us/step - loss: 0.1273 - accuracy: 0.9581 - val_loss: 0.1827 - val_accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 0s 649us/step - loss: 0.0941 - accuracy: 0.9627 - val_loss: 0.1761 - val_accuracy: 0.9286\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 0s 636us/step - loss: 0.1335 - accuracy: 0.9450 - val_loss: 0.1763 - val_accuracy: 0.9286\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 0s 623us/step - loss: 0.0979 - accuracy: 0.9628 - val_loss: 0.1741 - val_accuracy: 0.9345\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 0s 643us/step - loss: 0.0837 - accuracy: 0.9698 - val_loss: 0.1779 - val_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 0s 622us/step - loss: 0.0716 - accuracy: 0.9715 - val_loss: 0.1802 - val_accuracy: 0.9345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c0d9cc10>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['robust_Amount'] = robust_scale(df['Amount'])\n",
    "df['robust_Time'] = robust_scale(df['Time'])\n",
    "\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=492, random_state = 10)\n",
    "data = pd.concat([a, c])\n",
    "data\n",
    "\n",
    "df.head()\n",
    "\n",
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y_1, test_size = 0.15, random_state = 5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = 30, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "model.fit(x_train, y_train, validation_split = 0.2, epochs = 10, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96b519",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32878d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "57da8e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normal_Amount</th>\n",
       "      <th>normal_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-1.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>-1.986644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>-1.902623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>-1.849472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.838248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142905</th>\n",
       "      <td>-0.341475</td>\n",
       "      <td>0.900211</td>\n",
       "      <td>0.331773</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>3.184109</td>\n",
       "      <td>3.824945</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.577237</td>\n",
       "      <td>-0.819912</td>\n",
       "      <td>0.411051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>-0.281175</td>\n",
       "      <td>0.901199</td>\n",
       "      <td>-0.396459</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.266486</td>\n",
       "      <td>-0.266440</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350191</td>\n",
       "      <td>-0.206491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266742</th>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.250632</td>\n",
       "      <td>-0.146602</td>\n",
       "      <td>-0.603377</td>\n",
       "      <td>-0.289108</td>\n",
       "      <td>0.867031</td>\n",
       "      <td>-0.716845</td>\n",
       "      <td>0.916121</td>\n",
       "      <td>0.761860</td>\n",
       "      <td>-1.107982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682096</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>-0.396272</td>\n",
       "      <td>-1.105012</td>\n",
       "      <td>0.357460</td>\n",
       "      <td>-0.058522</td>\n",
       "      <td>-0.011369</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065367</td>\n",
       "      <td>1.424719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135785</th>\n",
       "      <td>-0.510727</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>1.619260</td>\n",
       "      <td>-0.063728</td>\n",
       "      <td>-0.287118</td>\n",
       "      <td>-0.758775</td>\n",
       "      <td>0.451503</td>\n",
       "      <td>0.193062</td>\n",
       "      <td>-0.337795</td>\n",
       "      <td>-0.081085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626206</td>\n",
       "      <td>0.039477</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>-0.320913</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.243857</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317287</td>\n",
       "      <td>-0.282510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284703</th>\n",
       "      <td>1.019594</td>\n",
       "      <td>-1.956473</td>\n",
       "      <td>-1.431268</td>\n",
       "      <td>0.539727</td>\n",
       "      <td>-0.499995</td>\n",
       "      <td>0.301251</td>\n",
       "      <td>0.326079</td>\n",
       "      <td>-0.062475</td>\n",
       "      <td>1.121288</td>\n",
       "      <td>-0.403165</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.202749</td>\n",
       "      <td>-0.182683</td>\n",
       "      <td>-1.075679</td>\n",
       "      <td>-0.417648</td>\n",
       "      <td>-1.080842</td>\n",
       "      <td>-0.049144</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0</td>\n",
       "      <td>1.733372</td>\n",
       "      <td>1.640099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49532</th>\n",
       "      <td>1.104568</td>\n",
       "      <td>-0.074271</td>\n",
       "      <td>0.268681</td>\n",
       "      <td>0.566325</td>\n",
       "      <td>-0.405835</td>\n",
       "      <td>-0.423311</td>\n",
       "      <td>-0.076164</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>-0.035610</td>\n",
       "      <td>0.128550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156076</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>0.223221</td>\n",
       "      <td>0.333878</td>\n",
       "      <td>0.398708</td>\n",
       "      <td>-0.045004</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.199623</td>\n",
       "      <td>-1.067865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "142905 -0.341475  0.900211  0.331773  0.813116  3.184109  3.824945  0.221303   \n",
       "266742  0.051338  0.250632 -0.146602 -0.603377 -0.289108  0.867031 -0.716845   \n",
       "135785 -0.510727  0.784119  1.619260 -0.063728 -0.287118 -0.758775  0.451503   \n",
       "284703  1.019594 -1.956473 -1.431268  0.539727 -0.499995  0.301251  0.326079   \n",
       "49532   1.104568 -0.074271  0.268681  0.566325 -0.405835 -0.423311 -0.076164   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "541     1.391657 -2.770089 -2.772272  ... -0.035049 -0.465211  0.320198   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.435477  1.375966 -0.293803   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.932391  0.172726 -0.087330   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.176968 -0.436207 -0.053502   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.704181 -0.656805 -1.632653   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "142905  0.577237 -0.819912  0.411051  ...  0.229812 -0.281175  0.901199   \n",
       "266742  0.916121  0.761860 -1.107982  ...  0.682096  0.262251 -0.396272   \n",
       "135785  0.193062 -0.337795 -0.081085  ... -0.626206  0.039477  0.455717   \n",
       "284703 -0.062475  1.121288 -0.403165  ... -1.202749 -0.182683 -1.075679   \n",
       "49532   0.094704 -0.035610  0.128550  ...  0.156076 -0.034111  0.223221   \n",
       "\n",
       "             V25       V26       V27       V28  Class  normal_Amount  \\\n",
       "541     0.044519  0.177840  0.261145 -0.143276      1      -0.353229   \n",
       "623     0.279798 -0.145362 -0.252773  0.035764      1       1.761758   \n",
       "4920   -0.156114 -0.542628  0.039566 -0.153029      1       0.606031   \n",
       "6108    0.252405 -0.657488 -0.827136  0.849573      1      -0.117342   \n",
       "6329    1.488901  0.566797 -0.010016  0.146793      1      -0.349231   \n",
       "...          ...       ...       ...       ...    ...            ...   \n",
       "142905 -0.396459 -0.097724 -0.266486 -0.266440      0      -0.350191   \n",
       "266742 -1.105012  0.357460 -0.058522 -0.011369      0      -0.065367   \n",
       "135785 -0.320913  0.048237  0.243857  0.109477      0      -0.317287   \n",
       "284703 -0.417648 -1.080842 -0.049144  0.039078      0       1.733372   \n",
       "49532   0.333878  0.398708 -0.045004  0.000546      0      -0.199623   \n",
       "\n",
       "        normal_Time  \n",
       "541       -1.988034  \n",
       "623       -1.986644  \n",
       "4920      -1.902623  \n",
       "6108      -1.849472  \n",
       "6329      -1.838248  \n",
       "...             ...  \n",
       "142905    -0.206491  \n",
       "266742     1.424719  \n",
       "135785    -0.282510  \n",
       "284703     1.640099  \n",
       "49532     -1.067865  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jjink/Desktop/python/data/creditcard.csv')\n",
    "\n",
    "df['normal_Amount'] = scale(df['Amount'])\n",
    "df['normal_Time'] = scale(df['Time'])\n",
    "df = df.drop(['Amount', 'Time'], axis = 1, inplace = False)\n",
    "\n",
    "a =  df[df['Class'] == 1]\n",
    "b = df[df['Class'] == 0]\n",
    "c = b.sample(n=492, random_state = 10)\n",
    "data = pd.concat([a, c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7227749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data['Class']\n",
    "x_1 = data.drop(['Class'], axis = 1, inplace = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y_1, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "acc470ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fe6dd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_test = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c2aed91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Fraud</th>\n",
       "      <th>Predicted Not Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Fraud</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Fraud  Predicted Not Fraud\n",
       "Fraud                   84                    8\n",
       "Not Fraud                3                  102"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_pred_test).ravel()\n",
    "conf_matrix = pd.DataFrame({'Predicted Fraud': [tp, fp],'Predicted Not Fraud': [fn, tn]}, index=['Fraud', 'Not Fraud'])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d696613f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2d313fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441624365482234 0.9655172413793104 0.9130434782608695 0.9385474860335196\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = accuracy_score(y_test, lr_pred_test)\n",
    "lr_precision = precision_score(y_test, lr_pred_test)\n",
    "lr_recall = recall_score(y_test, lr_pred_test)\n",
    "lr_f1 = f1_score(y_test, lr_pred_test)\n",
    "print(lr_accuracy, lr_precision, lr_recall, lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "79248521",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_test_prob = lr_model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ee7cb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, lr_pred_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1302265c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583850931677019"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_auc = roc_auc_score(y_test, lr_pred_test_prob)\n",
    "lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "54a3f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title('ROC Curve', fontsize=15)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.xticks(np.arange(0, 1, 0.05), rotation=90)\n",
    "    plt.xlabel('False Positive Rates', fontsize=15)\n",
    "    plt.ylabel('True Positive Rates', fontsize=15)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05d56644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr=fpr, tpr=tpr, label=\"AUC = %.3f\" % lr_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
