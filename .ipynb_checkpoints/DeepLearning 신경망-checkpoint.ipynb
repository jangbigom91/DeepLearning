{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b918fa",
   "metadata": {},
   "source": [
    "## 신경망에서 딥러닝으로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488af6d",
   "metadata": {},
   "source": [
    "#### ▪ 렐루(ReLU) 함수\n",
    "#### • 시그모이드 함수의 대안으로 떠오르며 현재 가장 많이 사용되는 활성화 함수임\n",
    "#### • 여러 은닉층을 거치며 곱해지더라도 맨 처음 층까지 사라지지 않고 남아있을 수 있음\n",
    "#### • 이 간단한 방법이 여러 층을 쌓을 수 있게 했고, 이로써 딥러닝의 발전에 속도가 붙게 됨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec60773",
   "metadata": {},
   "source": [
    "#### 고급 경사 하강법에서 현재 가장 많이 사용되는 것은 아담(Adam)\n",
    "#### 효과는 정확도와 보폭 크기 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a540faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실 함수값( 9.86 )= 57.05959999999999\n",
      "손실 함수값( 9.7228 )= 55.19603983999999\n",
      "손실 함수값( 9.588344 )= 53.40627666233599\n",
      "손실 함수값( 9.456577119999999 )= 51.68738810650748\n",
      "손실 함수값( 9.327445577599999 )= 50.03656753748979\n",
      "손실 함수값( 9.200896666048 )= 48.45111946300519\n",
      "손실 함수값( 9.076878732727039 )= 46.92845513227018\n",
      "손실 함수값( 8.955341158072498 )= 45.46608830903228\n",
      "손실 함수값( 8.836234334911047 )= 44.061631211994595\n",
      "손실 함수값( 8.719509648212826 )= 42.7127906159996\n",
      "손실 함수값( 8.60511945524857 )= 41.41736410760602\n",
      "손실 함수값( 8.493017066143599 )= 40.17323648894484\n",
      "손실 함수값( 8.383156724820727 )= 38.97837632398262\n",
      "손실 함수값( 8.275493590324313 )= 37.830832621552915\n",
      "손실 함수값( 8.169983718517827 )= 36.728731649739416\n",
      "손실 함수값( 8.06658404414747 )= 35.67027387640974\n",
      "손실 함수값( 7.965252363264521 )= 34.65373103090391\n",
      "손실 함수값( 7.865947315999231 )= 33.67744328208012\n",
      "손실 함수값( 7.768628369679246 )= 32.73981652810974\n",
      "손실 함수값( 7.673255802285661 )= 31.839319793596598\n",
      "손실 함수값( 7.579790686239948 )= 30.97448272977017\n",
      "손실 함수값( 7.488194872515149 )= 30.143893213671276\n",
      "손실 함수값( 7.398430975064846 )= 29.346195042409892\n",
      "손실 함수값( 7.3104623555635495 )= 28.580085718730462\n",
      "손실 함수값( 7.224253108452278 )= 27.844314324268737\n",
      "손실 함수값( 7.1397680462832325 )= 27.137679477027692\n",
      "손실 함수값( 7.056972685357568 )= 26.459027369737395\n",
      "손실 함수값( 6.975833231650417 )= 25.807249885895796\n",
      "손실 함수값( 6.896316567017409 )= 25.181282790414325\n",
      "손실 함수값( 6.818390235677061 )= 24.580103991913923\n",
      "손실 함수값( 6.7420224309635195 )= 24.00273187383413\n",
      "손실 함수값( 6.667181982344249 )= 23.448223691630297\n",
      "손실 함수값( 6.593838342697364 )= 22.915674033441732\n",
      "손실 함수값( 6.521961575843417 )= 22.404213341717444\n",
      "손실 함수값( 6.451522344326548 )= 21.91300649338543\n",
      "손실 함수값( 6.382491897440017 )= 21.44125143624737\n",
      "손실 함수값( 6.314842059491217 )= 20.988177879371975\n",
      "손실 함수값( 6.248545218301393 )= 20.553046035348846\n",
      "손실 함수값( 6.183574313935365 )= 20.13514541234903\n",
      "손실 함수값( 6.119902827656658 )= 19.73379365402001\n",
      "손실 함수값( 6.057504771103525 )= 19.34833542532082\n",
      "손실 함수값( 5.996354675681454 )= 18.97814134247811\n",
      "손실 함수값( 5.936427582167825 )= 18.62260694531598\n",
      "손실 함수값( 5.877699030524469 )= 18.28115171028147\n",
      "손실 함수값( 5.82014504991398 )= 17.953218102554324\n",
      "손실 함수값( 5.7637421489157 )= 17.63827066569317\n",
      "손실 함수값( 5.708467305937386 )= 17.335795147331723\n",
      "손실 함수값( 5.6542979598186385 )= 17.045297659497386\n",
      "손실 함수값( 5.601212000622266 )= 16.766303872181293\n",
      "손실 함수값( 5.54918776060982 )= 16.49835823884291\n",
      "손실 함수값( 5.498204005397624 )= 16.241023252584732\n",
      "손실 함수값( 5.448239925289672 )= 15.993878731782377\n",
      "손실 함수값( 5.399275126783878 )= 15.756521134003794\n",
      "손실 함수값( 5.3512896242482 )= 15.528562897097242\n",
      "손실 함수값( 5.304263831763236 )= 15.30963180637219\n",
      "손실 함수값( 5.258178555127971 )= 15.099370386839851\n",
      "손실 함수값( 5.213014984025412 )= 14.897435319520993\n",
      "손실 함수값( 5.168754684344903 )= 14.703496880867961\n",
      "손실 함수값( 5.125379590658005 )= 14.517238404385587\n",
      "손실 함수값( 5.082871998844845 )= 14.33835576357192\n",
      "손실 함수값( 5.0412145588679484 )= 14.166556875334473\n",
      "손실 함수값( 5.000390267690589 )= 14.001561223071228\n",
      "손실 함수값( 4.960382462336777 )= 13.843099398637605\n",
      "손실 함수값( 4.921174813090041 )= 13.690912662451556\n",
      "손실 함수값( 4.882751316828241 )= 13.544752521018475\n",
      "손실 함수값( 4.845096290491676 )= 13.404380321186142\n",
      "손실 함수값( 4.808194364681842 )= 13.269566860467172\n",
      "손실 함수값( 4.772030477388205 )= 13.140092012792671\n",
      "손실 함수값( 4.736589867840442 )= 13.015744369086082\n",
      "손실 함수값( 4.701858070483633 )= 12.896320892070275\n",
      "손실 함수값( 4.66782090907396 )= 12.78162658474429\n",
      "손실 함수값( 4.634464490892481 )= 12.671474171988416\n",
      "손실 함수값( 4.601775201074632 )= 12.565683794777676\n",
      "손실 함수값( 4.569739697053139 )= 12.46408271650448\n",
      "손실 함수값( 4.538344903112076 )= 12.366505040930903\n",
      "손실 함수값( 4.507578005049835 )= 12.27279144131004\n",
      "손실 함수값( 4.477426444948838 )= 12.182788900234161\n",
      "손실 함수값( 4.447877916049861 )= 12.096350459784889\n",
      "손실 함수값( 4.418920357728863 )= 12.013334981577405\n",
      "손실 함수값( 4.390541950574286 )= 11.933606916306939\n",
      "손실 함수값( 4.3627311115628 )= 11.857036082421185\n",
      "손실 함수값( 4.335476489331544 )= 11.783497453557306\n",
      "손실 함수값( 4.308766959544913 )= 11.712870954396436\n",
      "손실 함수값( 4.282591620354015 )= 11.64504126460234\n",
      "손실 함수값( 4.256939787946935 )= 11.579897630524087\n",
      "손실 함수값( 4.231800992187996 )= 11.517333684355332\n",
      "손실 함수값( 4.207164972344237 )= 11.457247270454863\n",
      "손실 함수값( 4.183021672897352 )= 11.39954027854485\n",
      "손실 함수값( 4.159361239439405 )= 11.344118483514473\n",
      "손실 함수값( 4.136174014650617 )= 11.290891391567301\n",
      "손실 함수값( 4.113450534357605 )= 11.239772092461235\n",
      "손실 함수값( 4.0911815236704525 )= 11.19067711759977\n",
      "손실 함수값( 4.0693578931970436 )= 11.143526303742819\n",
      "손실 함수값( 4.047970735333102 )= 11.098242662114604\n",
      "손실 함수값( 4.02701132062644 )= 11.054752252694865\n",
      "손실 함수값( 4.006471094213911 )= 11.012984063488148\n",
      "손실 함수값( 3.9863416723296328 )= 10.972869894574016\n",
      "손실 함수값( 3.9666148388830402 )= 10.934344246748886\n",
      "손실 함수값( 3.947282542105379 )= 10.897344214577629\n",
      "손실 함수값( 3.9283368912632715 )= 10.861809383680356\n",
      "최소값 =  3.9283368912632715\n"
     ]
    }
   ],
   "source": [
    "x = 10\n",
    "learning_rate = 0.01\n",
    "precision = 0.00001\n",
    "max_iterations = 100\n",
    "\n",
    "# 손실 함수를 람다식으로 정의한다.\n",
    "loss_func = lambda x: (x-3) ** 2 + 10\n",
    "\n",
    "# 그래디언트를 람다식으로 정의한다. 손실 함수의 1차 미분값이다.\n",
    "gradient = lambda x: 2 * x - 6\n",
    "\n",
    "# 그래디언트 강하법\n",
    "for i in range(max_iterations):\n",
    "    x = x - learning_rate * gradient(x)\n",
    "    print(\"손실 함수값(\", x, \")=\", loss_func(x))\n",
    "    \n",
    "print(\"최소값 = \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daaf681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04685\n",
      "0.6931471803599453\n",
      "8.265472039806522\n",
      "21.21844021456322\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MSE(y, t):\n",
    "    return 0.5 * np.sum((y-t) ** 2)\n",
    "\n",
    "t = np.array([0, 0, 0, 0.5, 0.5, 0, 0, 0, 0, 0])\n",
    "yr = np.array([0, 0, 0, 0.5, 0.5, 0, 0, 0, 0, 0])\n",
    "y = np.array([0.01, 0.01, 0.1, 0.3, 0.33, 0.04, 0.02, 0.05, 0.01, 0.1])\n",
    "y_1 = np.array([0.3, 0.01, 0.1, 0.01, 0.04, 0.02, 0.05, 0.33, 0.01, 0.1])\n",
    "\n",
    "\n",
    "def CEE(y, t):\n",
    "    delta = 1e-10\n",
    "    return -np.sum(t*np.log(y+delta))\n",
    "\n",
    "print(MSE(t,y))\n",
    "print(CEE(t, yr))\n",
    "print(CEE(t,y))\n",
    "print(CEE(t,y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b9990",
   "metadata": {},
   "source": [
    "#### • 입력층과 출력층 사이에 은닉층(hidden layer)을 가지고 있는 신경망을 다층 퍼셉트론(multilayerperceptron: MLP)이라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8152f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0967 - acc: 0.2011\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0854 - acc: 0.4190\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0799 - acc: 0.5324\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0735 - acc: 0.5974\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0673 - acc: 0.6508\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0616 - acc: 0.6873\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0567 - acc: 0.7195\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0528 - acc: 0.7472\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0493 - acc: 0.7695\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0465 - acc: 0.7898\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0444 - acc: 0.8024\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0424 - acc: 0.8119\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0406 - acc: 0.8209\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0391 - acc: 0.8295\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0378 - acc: 0.8336\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0363 - acc: 0.8427\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0356 - acc: 0.8430\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0347 - acc: 0.8453\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0336 - acc: 0.8517\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0329 - acc: 0.8531\n",
      "테스트 손실값: 0.03147835284471512\n",
      "테스트 정확도: 0.8640000224113464\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 128   # 가중치를 변경하기 전에 처리하는 샘플의 개수\n",
    "num_classes = 10   # 출력 클래스의 개수\n",
    "epochs = 20   # 에포크의 개수\n",
    "\n",
    "# 데이터를 학습 데이터와 테스트 데이터로 나눈다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 입력이미지를 2차원에서 1차원 벡터로 변경한다.\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# 입력 이미지의 픽셀 값이 0.0에서 1.0사이의 값이 되게한다.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# 클래스의 개수에 따라서 하나의 출력 픽셀만이 1이 되게 한다.\n",
    "# 예를 들면 1 0 0 0 0 0 0 0 0 0과 같다.\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# 신경망의 모델을 구축한다.\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "model.summary()\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.1)\n",
    "\n",
    "# 손실 함수를 제곱 오차 함수로 설정하고 학습 알고리즘은 SGD 방식으로 한다.\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['acc'])\n",
    "\n",
    "# 학습을 수행한다.\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# 학습을 평가한다.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('테스트 손실값:', score[0])\n",
    "print('테스트 정확도:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957e45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
